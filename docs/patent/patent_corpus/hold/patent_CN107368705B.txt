## Patent Reference

- Title: Methods and computer systems for analyzing genomic DNA of organisms
- URL: https://patents.google.com/patent/CN107368705B/en

### Abstract

Abstract Translated from Chinese 本发明涉及用于分析核酸序列数据的逻辑，其采用导致序列准确度实质性改善，并且可以例如与长片段读取结果(LFR)方法的使用结合使用以对序列变异定相的算法。 The present invention relates to logic for analyzing nucleic acid sequence data that employs algorithms that result in substantial improvements in sequence accuracy and that can be used, for example, in conjunction with the use of long fragment reads (LFR) methods to phase sequence variation.

### Description

Description Method and computer system for analyzing genomic DNA of organismThe application is a divisional application with application date of 2012, 13/04, application number of '201280029331.7' (PCT application number of PCT/US2012/033686) and invented name of 'processing and analyzing complex nucleic acid sequence data'. Cross reference to related applications This application claims priority to U.S. provisional patent application No.61/517,196, filed on 14/4/2011, which is incorporated herein by reference in its entirety. This application claims priority to U.S. provisional patent application No.61/527,428, filed on 25/8/2011, which is incorporated herein by reference in its entirety. This application claims priority to U.S. provisional patent application No.61/546,516 filed on 12.10.2011, which is incorporated herein by reference in its entirety. Background There is a need for improved techniques for analyzing complex nucleic acids, such as methods for improving sequence accuracy and for analyzing sequences with a large amount of error introduced via nucleic acid amplification, among others. Furthermore, there is a need for improved techniques for determining parental contributions to the genome of higher organisms, i.e. haplotype phasing (phasing), of the human genome. Methods for haplotype phasing, including computational methods and experimental phasing, are reviewed in Browning and Browning, Nature Reviews Genetics12:703-7014, 2011. Summary of The Invention The present invention provides techniques for analyzing sequence information derived from complex nucleic acid sequencing (as defined herein) that result in haplotype phasing, error reduction, and other features, developed based on algorithms and analysis techniques, in conjunction with long fragment read results (LFR) techniques. In accordance with one aspect of the present invention, methods are provided for determining the sequence of a complex nucleic acid (e.g., a whole genome) of one or more organisms (i.e., an individual organism or a population of organisms). Such methods include: (a) receiving, at one or more computing devices, a plurality of reads of a complex nucleic acid; and (b) generating, with a computing device, from the reads, an assembled sequence of complex nucleic acids comprising less than 1.0,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0.08,0.07,0.06,0.05, or 0.04 pseudo single nucleotide variants per megabase at a response rate of 70,75,80,85,90, or 95% or more, wherein the method is performed by one or more computing devices. In some aspects, a computer-readable non-transitory storage medium stores one or more sequences of instructions comprising instructions which, when executed by one or more computing devices, cause the one or more computing devices to perform the steps of such methods. According to one embodiment, wherein such methods involve haplotype phasing, the method further comprises identifying a plurality of sequence variants in the assembled sequence and phasing the sequence variants (e.g., 70,75,80,85,90, 95% or more of the sequence variants) to produce phased sequences, i.e., sequences phased to the sequence variants. Such phasing information can be used in the context of error correction. For example, according to one embodiment, such methods comprise identifying as an error a sequence variant that is inconsistent with the phasing of at least two (or three or more) phased sequence variants. According to another such embodiment, in such methods, the step of receiving a plurality of reads of the complex nucleic acid comprises a computing device and/or computer logic thereof receiving a plurality of reads from each of a plurality of aliquots, each aliquot comprising one or more fragments of the complex nucleic acid. Information on providing an aliquot of such fragments can be used to correct for errors or responsive bases that would otherwise be 'non-responsive'. According to one such embodiment, such methods comprise a computing device and/or computer logic thereof that responds to bases at positions of the assembled sequence based on preliminary base responses (preliminary base calls) from the positions of two or more aliquots. For example, a method can include responding to bases at a position in the assembled sequence based on preliminary base responses from at least two, at least three, at least four, or more than four aliquots. In some embodiments, such methods may comprise identifying a base response as true if it is present in at least two, at least three, at least four aliquots, or more than four aliquots. In some embodiments, such methods may comprise identifying a base response as authentic if it is present in at least a majority (or at least 60%, at least 75%, or at least 80%) of the aliquots making the preliminary base response to the location in the assembled sequence. In accordance with another such embodiment, such methods include a computing device and/or computer logic thereof that identifies a base response as authentic when the base response is present three or more times in reads from two or more aliquots. According to another such embodiment, the aliquot from which the read originated is determined by identifying the aliquot-specific tag (or set of aliquot-specific tags) attached to each fragment. Optionally, such aliquot-specific labels comprise an error correction or error detection code (e.g., Reed-Solomon error correction code). According to one embodiment of the invention, after sequencing the fragments and attached aliquot-specific tags, the resulting reads comprise tag sequence data and fragment sequence data. If the tag sequence data is correct, i.e., if the tag sequence data matches a tag sequence used for aliquot identification, or alternatively if the tag sequence data has one or more errors that can be corrected using an error correction code, then reads comprising such tag sequence data can be used for all purposes, particularly for a first computer method (e.g., executing on one or more computing devices) that requires the tag sequence data and produces a first output, including but not limited to haplotype phasing, sample multiplexing, library multiplexing, phasing, or any error correction method based on the correct tag sequence data (e.g., an error correction method based on an aliquot identifying the origin of a particular read). If the tag sequence is incorrect and cannot be corrected, the read results containing such incorrect tag sequence data are not discarded and used in a second computer method (e.g., executed by one or more computing devices) that does not require tag sequence data, including but not limited to localization, assembly, and set-based statistics, and produces a second output. According to another embodiment, such methods further comprise: a computing device and/or computer logic thereof that provides a first phased sequence of a region of a complex nucleic acid, the region comprising a short tandem repeat; computing means and/or computer logic thereof to compare the reads of the first phased sequence of the region (e.g., regular or mate-pair reads) with the reads of the second phased sequence of the region (e.g., using sequence coverage); and identifying a computing device and/or computer logic thereof for short tandem repeat expansion in one of the first phased sequence or the second phased sequence based on the comparison. According to another embodiment, the method further comprises a computing device and/or computer logic thereof that obtains genotype data from at least one parent of the organism and generates an assembled sequence of complex nucleic acids from the reads and the genotype data. According to another embodiment, the method further comprises a computing device and/or computer logic thereof implementing steps comprising: aligning a plurality of the reads against a first region of the complex nucleic acid, thereby creating an overlap between aligned reads; identifying N heterozygous candidates within the overlap; cluster 2 NTo 4NA space of possibilities or a selected subspace thereof, thereby creating a plurality of clusters; identifying two clusters having the highest density, each identified cluster comprising a substantially noiseless center; and to saidThe foregoing steps are repeated for one or more additional regions of the complex nucleic acid. The clusters identified for each region may define contigs, and these contigs may be matched to each other to form contigs, one representing each haplotype. According to another embodiment, such methods further comprise providing an amount of the complex nucleic acid, and sequencing the complex nucleic acid to generate a read. According to another embodiment, in such methods, the complex nucleic acid is selected from the group consisting of: genomes, exomes (exosomes), transcriptomes, methylation groups (methylomes), mixtures of genomes of different organisms, and mixtures of genomes of different cell types of an organism. In accordance with another aspect of the present invention, there is provided an assembled human genomic sequence produced by any of the above methods. For example, one or more computer-readable non-transitory storage media store assembled human genomic sequences produced by any of the above methods. According to another aspect, a computer-readable non-transitory storage medium stores one or more sequences of instructions which include instructions which, when executed by one or more computing devices, cause the one or more computing devices to perform any, some or all of the above-described methods. In accordance with another aspect of the present invention, there is provided a method for determining a human whole genome sequence, such method comprising: (a) receiving, at one or more computing devices, a plurality of reads of the genome; and (b) generating, with the one or more computing devices, an assembled sequence of the genome from the reads, the assembled sequence comprising less than 600 pseudo-hybrid single nucleotide variants per gigabase at a genome response rate of 70% or greater; according to one embodiment, the assembled sequence of the genome has a genome response rate of 70% or more and an exome response rate of 70% or more. In some aspects, a computer-readable non-transitory storage medium stores one or more sequences of instructions comprising instructions which, when executed by one or more computing devices, cause the one or more computing devices to perform any of the inventive methods described herein. In accordance with another aspect of the present invention, there is provided a method for determining a human whole genome sequence, such method comprising: (a) receiving, at one or more computing devices, a plurality of reads from each of a plurality of aliquots, each aliquot comprising one or more fragments of a genome; and (b) generating, with the one or more computing devices, phased assembled sequences of the genome comprising less than 1000 pseudo single nucleotide variants per gigabase at a genome response rate of 70% or greater from the reads. In some aspects, a computer-readable non-transitory storage medium stores one or more sequences of instructions comprising instructions which, when executed by one or more computing devices, cause the one or more computing devices to perform such methods. Brief Description of Drawings FIGS. 1A and 1B show examples of sequencing systems. FIG. 2 shows an example of a computing device that may be used in or in conjunction with a sequencer and/or computer system. Fig. 3 shows the general architecture of the LFR algorithm. FIG. 4 shows pairwise analysis of neighboring heterozygous SNPs. Fig. 5 shows an example of selecting a hypothesis and attributing a score to the hypothesis. Figure 6 shows the map construction. Figure 7 shows graph optimization. Figure 8 shows the contig alignment. Figure 9 shows parental assisted universal phasing. FIG. 10 shows natural contig separation. Fig. 11 shows the general phasing. Fig. 12 shows error detection using LFR. FIG. 13 shows an example of a method to reduce the number of false negatives, where a reliable heterozygous SNP response can be generated regardless of how small the number of reads is. FIG. 14 shows the detection of expansion of CTG repeats in human embryos by clonal coverage of analytical haplotypes (expansion). FIG. 15 is a graph showing the amplification of purified genomic DNA standards (1.031, 8.25 and 66 picograms [ pg ]) and 1 or 10 PVP40 cells using a Multiple Displacement Amplification (MDA) protocol, as described in example 1. Figure 16 shows data relating to GC preference amplified using two MDA protocols. The average number of cycles across the entire plate was determined and subtracted from each individual marker to calculate the 'delta cycle' number. The delta cycles are plotted against the GC content of 1000 base pairs surrounding each marker to indicate the relative GC preference of each sample (not shown). The absolute values of each delta cycle are summed to create a 'delta sum' metric. The lower sum Δ, and the relatively flat curve of data versus GC content, produced a better rendered whole genome sequence. Δ sums are 61 (for our MDA method) and 287 (for SurePlex amplified DNA), indicating that our protocol produces much less GC preference than SurePlex protocol. Fig. 17 shows the genomic coverage of samples 7C and 10C. Coverage was plotted using a 10 megabase moving average of a 100 kilobase coverage window normalized to haploid genome coverage. The dashed lines at copy numbers 1 and 3 represent haploid and triploid copy numbers, respectively. These two embryos are male and have haploid copy numbers for the X and Y chromosomes. No other loss or gain of whole chromosomes or large segments of chromosomes was found in these samples. FIG. 18 is a schematic representation of an embodiment of a barcode adaptor design for use in the methods of the invention. The LFR adaptors consist of a unique 5 ' barcode adaptor, a common 5 ' adaptor, and a common 3 ' adaptor. The common adaptors are all designed to have 3 'dideoxynucleotides that cannot be ligated to 3' fragments, which eliminates the formation of adaptor dimers. After ligation, the blocking portion of the adaptor is removed and replaced with an unblocked oligonucleotide. The remaining nicks were resolved by subsequent nick translation with Taq polymer and ligation with T4 ligase. Fig. 19 shows the cumulative GC coverage. Cumulative coverage of GCs was plotted against LFR and standard library to compare GC bias differences. For sample NA19240(a and b), 3 LFR pools (repeat 1, repeat 2, and 10 cells) and 1 standard pool were plotted for both the entire genome (c) and the coding part only (d). In all LFR pools, loss of coverage in the high GC regions is evident, which is more evident in the coding regions (b and d) containing a higher proportion of GC-rich regions. FIG. 20 shows a comparison of haplotype performance between genomic assemblies. The variant responses of the standard assembly library and the LFR assembly library were combined and used as loci for phasing, except where specified. LFR phasing rates were based on the calculation of parent phasing heterozygous SNPs. For those individuals without parental genomic data (NA12891, NA12892, and NA20431), the phasing ratio was calculated by dividing the number of phased heterozygous SNPs by the number of heterozygous SNPs expected to be true (the number of SNPs attempted to be phased-50,000 expected errors). N50 calculation was based on the total assembly length of all contigs relative to NCBI building block 36 (building block 37 in the case of NA1924010 cells and high coverage and NA20431 high coverage). Haploid fragment coverage was 4 times greater than cell number due to all DNA being dispersed on 384-well plates after denaturation to single strands. The insufficient amount of starting DNA explains the lower phasing efficiency in the NA20431 genome. Samples of #10 cells were measured by coverage of individual wells containing more than 10 cells, which may be the result of these cells at various stages of the cell cycle during collection. The phasing ratio ranged from 84% to 97%. Fig. 21 shows the LFR cell-typing algorithm. (a) Extracting variables: variables are extracted from the labeled aliquot reads. The 10 base Reed-Solomon code ensures that tag recovery can be achieved via error correction. (b) Evaluation of the connectivity of heterozygous SNP pairs: for each heterozygous SNP pair within a certain neighborhood, a matrix of shared aliquots is calculated. Loop 1 is the overall heterozygous SNP on one chromosome. Loop 2 is the global heterozygous SNP located in the neighborhood of the heterozygous SNP of Loop 1 on the chromosome. This neighborhood is limited by the number of expected heterozygous SNPs and the expected fragment length. (c) And (3) generation of a graph: an undirected graph is generated in which nodes correspond to heterozygous SNPs, while junctions (connections) correspond to the direction (orientation) and strength of the best hypothesis for the relationships between those SNPs. (as used herein, a 'node' is data [ a data item or data object ] that may have one or more numerical values representing base response or other sequence variation (e.g., heterozygosity or indels) in a polynucleotide sequence.) the orientation is binary (binary). FIG. 21 depicts the flipped and flipped relationships between heterozygous SNP pairs, respectively. The intensity is defined by applying fuzzy logic operations to the elements sharing the aliquot matrix. (d) Optimizing the graph: the graph is optimized via minimum spanning tree operations. (e) Contig generation: each subtree is reduced to a contig by leaving the first heterozygous SNP unchanged and flipping or not flipping other heterozygous SNPs on the subtree based on their path to the first heterozygous SNP. Assigning parent 1(P1) and parent 2(P2) to each contig is arbitrary. Gaps in the whole chromosome tree define the boundaries of different subtrees/contigs on the chromosome. (f) Mapping LFR contigs to parent chromosomes: using parental information, maternal or paternal tags were placed on the P1 and P2 haplotypes of each contig. FIG. 22 shows haplotype inconsistency between duplicate LFR libraries. Two duplicate libraries from samples NA12877 and NA19240 were compared at all shared phased heterozygous SNP loci. This is a comprehensive comparison, as most phased loci are shared between the two libraries. Fig. 23 shows the error reduction achieved by LFR. Standard library heterozygous SNP responses alone, and combinations with LFR responses, are phased independently by repeating LFR libraries. Typically, LFRs introduce about 10-fold more false positive variant responses. This most likely occurs due to random incorporation of incorrect bases during phi 29-based multiplex displacement amplification. Importantly, if it is required that the heterozygous SNP response must be phased and visible in three or more separate wells, the reduction in error is significant and the result is also better than the standard library without error correction. LFR can also remove errors from standard libraries, which improves response accuracy by a factor of about 10. Fig. 24 shows the LFR re-response for the unresponsive location. To demonstrate the potential of LFR to rescue unresponsive locations, three example locations were selected on chromosome 18 that were unresponsive (not responding) by standard software. These positions can be partially or fully responded to by phasing them with C/T heterozygous SNPs that are part of the LFR contig. The distribution of shared wells (those with at least one read for each of the paired bases; 16 pairs for the locus evaluated) allows for re-response of the three N/N positions into A/N, C/C and T/C responses and defines C-A-C-T and T-N-C-C as haplotypes. The use of well information allows the LFR to respond accurately to alleles with as few as 2-3 reads out of 2-3 expected wells (about 3-fold less than in the case of non-well information). FIG. 25 shows the number of genes with multiple unfavorable variations in each analyzed sample. FIG. 26 shows genes with allelic expression differences in NA20431 and with SNPs that alter TFBS. In a non-exhaustive list of genes that demonstrated significant allelic expression differences, 6 genes were found to have SNPs that could alter TFBS, which correlated with the observed differences in expression between alleles. All positions are given relative to NCBI component 37. 'CDS' represents the coding sequence and 'UTR 3' represents the 3' untranslated region. Detailed Description As used herein and in the appended claims, the singular forms 'a,' 'an,' and 'the' include plural referents unless the context clearly dictates otherwise. Thus, for example, reference to 'a polymerase' refers to one reagent or a mixture of such reagents, and reference to 'the method' includes reference to equivalent steps and/or methods known to those skilled in the art, and so forth. Unless defined otherwise, all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this invention belongs. For the purpose of describing and disclosing the devices, compositions, formulations, and methods described in the publications and which might be used in connection with the presently described methods, all publications mentioned herein are incorporated by reference. Where a range of values is provided, it is understood that the invention contemplates each intervening value, to the tenth of the unit of the lower limit unless the context clearly dictates otherwise, between the upper and lower limit of that range and any other stated or intervening value in that stated range. The upper and lower limits of these smaller ranges may independently be included, and the smaller ranges are also encompassed within the invention, subject to any specifically excluded limit in the stated range. Where a stated range includes one or both of the limits, ranges excluding either or both of those included limits are also included in the invention. In the following description, numerous specific details are set forth in order to provide a more thorough understanding of the present invention. It will be apparent, however, to one skilled in the art, that the present invention may be practiced without one or more of these specific details. In other instances, well-known features and procedures well known to those skilled in the art have not been described in order to avoid obscuring the present invention. Although the invention has been described primarily with reference to specific embodiments, it is also contemplated that other embodiments will become apparent to those skilled in the art upon reading the present disclosure, and that such embodiments are intended to be included within the methods of the invention. Sequencing system and data analysis In some embodiments, sequencing of a DNA sample (e.g., such as a sample representing a whole human genome) can be performed by a sequencing system. Two examples of sequencing systems are shown in FIG. 1. Fig. 1A and 1B are block diagrams of an example sequencing system 190, the sequencing system 190 configured to implement techniques and/or methods for nucleic acid sequence analysis according to embodiments described herein. Sequencing system 190 can comprise or be in communication with a plurality of subsystems, such as, for example, one or more sequencers such as sequencer 191, one or more computer systems such as computer system 197, and one or more data repositories such as data repository 195. In the embodiment shown in fig. 1A, the various subsystems of the system 190 may be communicatively connected by one or more networks 193, which networks 193 may include packet-switched or other types of network infrastructure devices (e.g., routers, switches, etc.) configured to facilitate the exchange of information between remote systems. In the embodiment shown in fig. 1B, the sequencing system 190 is a sequencing device in which multiple subsystems (such as, for example, a sequencer 191, a computer system 197, and possibly a data repository 195) are communicatively and/or operationally coupled and integrated components within the sequencing device. In some operational contexts, the data repository 195 and/or computer system 197 of the embodiments shown in fig. 1A and 1B may be configured within a cloud computing environment 196. In a cloud computing environment, storage devices containing data repositories and/or computing devices containing computer systems can be allocated and instantiated for use as utilities and as needed; as such, the cloud computing environment provides infrastructure (e.g., physical and virtual machines, raw/block storage, firewalls, load balancers, aggregators (aggregators), networks, storage clusters (storage clusters), and the like), platforms (e.g., computing devices and/or solution stacks (solution stacks) that may contain operating systems, programming language execution environments, database servers, web servers, application servers, and the like), and software (e.g., applications, application programming interfaces or APIs, and the like) as services necessary to carry out any storage-related and/or computing tasks. It is noted that in various embodiments, the techniques described herein may be implemented by various systems and devices that include some or all of the above-described subsystems and components (e.g., such as sequencers, computer systems, and data repositories) in various configurations and form factors; as such, the example embodiments and configurations shown in fig. 1A and 1B should be viewed in an illustrative and non-limiting sense. The sequencer 191 is configured and operable to receive the target nucleic acid 192 derived from the biological sample fragment and to sequence the target nucleic acid. Any suitable machine that can perform sequencing may be used, where such a machine may use a variety of sequencing techniques, including but not limited to sequencing by hybridization, sequencing by ligation, sequencing by synthesis, single molecule sequencing, optical sequence detection, electromagnetic sequence detection, voltage change sequence detection, and any other now known or later developed technique suitable for generating read sequencing results from DNA. In various embodiments, a sequencer can sequence a target nucleic acid and can generate a read sequencing result, which may or may not contain gaps, and which may or may not be a pair-pair (or pair-end) read. As shown in fig. 1A and 1B, the sequencer 191 sequences a target nucleic acid 192 and obtains read sequencing results 194 that are transmitted for storage (temporarily and/or permanently) in one or more data repositories 195 and/or processing by one or more computer systems 197. Data repository 195 may execute on one or more storage devices (e.g., hard disk drives, optical disks, solid state drives, etc.) that may be configured as a disk array (e.g., such as a SCSI array), a storage cluster, or any other suitable storage device configuration. The storage devices of the data repository may be configured as internal/integrated components of the system 190 or external components attachable to the system 190 (e.g., such as an external hard drive or disk array) (e.g., as shown in fig. 1B), and/or may be communicatively interconnected in a suitable manner, such as, for example, a grid, a storage cluster, a Storage Area Network (SAN), and/or a Network Attached Storage (NAS) (e.g., as shown in fig. 1A). In various embodiments and implementations, the data repository may execute on the storage device in one or more file systems that store information in files, in one or more databases that store information in data records, and/or in any other suitable data storage configuration. Computer system 197 may include one or more computing devices including a general purpose processor (e.g., a central processing unit or CPU), memory, and computer logic 199, which together with configuration data and/or Operating System (OS) software may implement some or all of the techniques and methods described herein, and/or may control the operation of sequencer 191. For example, any of the methods described herein (e.g., for error correction, haplotype phasing, etc.) can be implemented in whole or in part by a computing device comprising a processor that can be configured to execute logic 199 for implementing the various methods of the method. Further, while method steps may be presented as numbered steps, it should be understood that the steps of the methods described herein may be performed simultaneously (e.g., in parallel by a cluster of computing devices) or in a different order. The functionality of computer logic 199 may be performed in a single integrated module (e.g., in integrated logic) or may be combined in two or more software modules, which may provide some other functionality. In some embodiments, computer system 197 may be a single computing device. In other embodiments, computer system 197 may comprise a plurality of computing devices, which may communicate and/or be operably interconnected in a grid, cluster, or cloud computing environment. Such multiple computing devices may be configured in different form factors (form factors) such as compute nodes, blades (blades), or any other suitable hardware configuration. For these reasons, the computer system 197 in FIGS. 1A and 1B should be viewed in an illustrative and non-limiting sense. Fig. 2 is a block diagram of an example computing device 200 that is part of a sequencer and/or computer system, which computing device 200 may be configured to execute instructions for implementing various data processing and/or control functionality. In fig. 2, computing device 200 contains several components that are interconnected directly or indirectly through one or more system buses, such as bus 275. Such components may include, but are not limited to, a keyboard 278, a persistent storage device 279 (e.g., such as a fixed disk, a solid state disk, an optical disk, etc.), and a display adapter 282, to which one or more display devices (e.g., such as an LCD monitor, a flat panel monitor, a plasma screen, etc.) may be coupled. Peripheral devices and input/output (I/O) devices (coupled to I/O controller 271) may be connected to computing device 200 by any of a variety of means known in the art, including, but not limited to, one or more serial ports, one or more parallel ports, and one or more Universal Serial Buses (USB). external interface 281, which may include a network interface card and/or serial port, may be used to connect computing device 200 to a network (such as, for example, the Internet or a Local Area Network (LAN)) And (4) changing. The system memory 272 and/or the storage device 279 may be embodied as one or more computer-readable non-transitory storage media that store sequences of instructions and other data for execution by the processor 273. Such computer-readable non-transitory storage media include, but are not limited to, Random Access Memory (RAM), Read Only Memory (ROM), electromagnetic media (such as, for example, a hard disk drive, a solid state drive, thumb drive, floppy disk, etc.), optical media such as a Compact Disk (CD) or Digital Versatile Disk (DVD), flash memory, and the like. Various data values and other structured or unstructured information may be output from one component or subsystem to another, may be presented to a user via display adapter 282 and a suitable display device, may be sent over a network to a remote device or remote data repository via external interface 281, or be stored (temporarily and/or permanently) on storage device 279. Any methods and functionality implemented by the computing device 200 can be performed in a logical form using hardware and/or computer software in a modular or integrated manner. As used herein, 'logic' refers to a set of instructions operable, when executed by one or more processors (e.g., CPUs) of one or more computing devices, to implement one or more functionalities and/or return data in the form of one or more results or data used by other logic elements. In various embodiments and implementations, any given logic may be implemented as one or more software components executable by one or more processors (e.g., CPUs), as one or more hardware components such as Application-Specific Integrated circuits (ASICs) and/or Field-Programmable Gate arrays (FPGAs), or as any combination of one or more software components and one or more hardware components. Software components of any particular logic may be restricted to executing as a stand-alone software application, as a client in a client-server system, as a server in a client-server system, as one or more software modules, as one or more functional libraries, and as one or more static and/or dynamic connection libraries. During execution, the instructions of any particular logic may be embodied as one or more computer processes, threads, fibers, and any other suitable runtime entity that may be instantiated on hardware of one or more computing devices and may be allocated computing resources that may include, but are not limited to, memory, CPU time, storage space, and network bandwidth. Techniques and algorithms for LFR processes Base response General methods for sequencing a target nucleic acid using the compositions and methods of the invention are described herein and, for example, in U.S. patent application publication 2010/0105052-A1; published patent application numbers WO2007120208, WO2006073504, WO2007133831 and US2007099208 and US patent application No.11/679,124; 11/981,761, respectively; 11/981,661, respectively; 11/981,605, respectively; 11/981,793, respectively; 11/981,804, respectively; 11/451,691, respectively; 11/981,607, respectively; 11/981,767, respectively; 11/982,467, respectively; 11/451,692, respectively; 11/541,225, respectively; 11/927,356, respectively; 11/927,388, respectively; 11/938,096, respectively; 11/938,106, respectively; 10/547,214, respectively; 11/981,730, respectively; 11/981,685, respectively; 11/981,797, respectively; 11/934,695, respectively; 11/934,697, respectively; 11/934,703, respectively; 12/265,593, respectively; 11/938,213, respectively; 11/938,221, respectively; 12/325,922, respectively; 12/252,280, respectively; 12/266,385, respectively; 12/329,365, respectively; 12/335,168, respectively; 12/335,188, respectively; and 12/361,507, which are herein incorporated by reference in their entirety for all purposes. Also seen is Drmanac et al, Science 327,78-81,2010. Long Fragment Reading (LFR) methods have been disclosed in U.S. patent application nos. 12/816,365,12/329,365,12/266,385, and 12/265,593 and U.S. patent nos. 7,906,285,7,901,891, and 7,709,197, which are hereby incorporated by reference in their entirety. Further details and improvements are provided herein. In some embodiments, data extraction may rely on two types of image data: bright field images of all DNB locations on the surface were divided, and a set of fluorescence images obtained during each sequencing cycle. Data extraction software can be used to identify all objects with bright field images, and then for each such object, the software can be used to calculate the average fluorescence value for each sequencing cycle. For any given cycle, there are four data points, corresponding to four images taken at different wavelengths, to query whether the base is A, G, C or T. These raw data points (also referred to herein as 'base responses') were pooled to generate a discrete read sequencing result for each DNB. The computing device can be equipped to identify a population of bases to provide sequence information about the target nucleic acid and/or to identify the presence of a particular sequence in the target nucleic acid. For example, a computing device can identify a population of bases by executing various logic to assemble in accordance with the techniques and algorithms described herein; examples of such logic are software code written in any suitable programming language, such as Java, C + +, Perl, Python, and any other suitable conventional and/or object-oriented programming language. When executed in one or more computer processes, such logic may read results, write, and/or otherwise process structured and unstructured data, which may be stored in various structures on persistent storage and/or in volatile memory; examples of such storage structures include, but are not limited to, files, tables, database records, arrays, lists, vectors, arguments, memory and/or processor registers, persistent and/or memory data objects instantiated from object-oriented classes, and any other suitable data structures. In some embodiments, the identified bases are assembled into a complete sequence by aligning overlapping sequences obtained from multiple sequencing cycles performed on multiple DNBs. As used herein, the term 'complete sequence' refers to sequences of part or the entire genome and part or the entire target nucleic acid. In other embodiments, the assembly method implemented by one or more computing devices or computer logic thereof utilizes an algorithm that can be used to 'piece together' overlapping sequences to provide a complete sequence. In still other embodiments, a reference table is used to aid in the assembly of the identified sequences into a complete sequence. The reference table may be compiled using existing sequencing data for the selected organism. For example, human genomic data can be centered on ftp. The entire human genomic information or a subset of the human genomic information may be used to create a reference table for a particular sequencing query. In addition, a particular reference table may be constructed from empirical data derived from a particular population, including genetic sequences from humans with a particular ethnic, geotraditional, religious, or cultural defined population, as variations within the human genome may skew the reference data as the origin of the information contained therein. Exemplary methods for responding to Variations in a Polynucleotide Sequence compared to a Reference Polynucleotide Sequence and for Polynucleotide Sequence assembly (or reassembly) are provided, for example, in U.S. patent publication No.2011-0004413, entitled 'Method and System for calcium variants in a Sample Polynucleotide Sequence with resource to a Reference Polynucleotide Sequence,' which is incorporated herein by Reference for all purposes. In any of the embodiments of the invention discussed herein, the nucleic acid template and/or the population of DNBs may comprise a number of target nucleic acids to cover substantially the entire genome or the entire target polynucleotide. As used herein, 'substantially covers' means that the amount of nucleotides (i.e., target sequence) analyzed contains an equivalent of at least two copies of the target polynucleotide, or in another aspect, at least 10 copies, or in another aspect, at least 20 copies, or in another aspect, at least 100 copies. The target polynucleotide may comprise DNA fragments, including genomic DNA fragments and cDNA fragments as well as RNA fragments. Guidance for steps for reconstructing a target polynucleotide sequence can be found in the following references, which are incorporated by reference: lander et al, Genomics,2: 231-; vintron et al, J.mol.biol.,235:1-12 (1994); and the like. In some embodiments, four images are generated for each interrogation position of the sequenced complex nucleotide, one for each color dye. The position of each point in the image and the resulting intensity of each of the four colors were determined by adjusting the cross-talk between the dye and the background intensity. A quantitative model may be fitted to the resulting four-dimensional dataset. Response bases to a given point are given a quality score that reflects how well the four intensities fit the model. The base response of the four images of each field of view may be performed in several steps by one or more computing devices or computer logic thereof. First, the image intensity is corrected for the background using a modified morphological 'image on' operation. Since the location of the DNB is lined up with the camera pixel location, the intensity extraction is done as a simple reading of the pixel intensity from the background corrected image. These intensities are then corrected for several sources of both optical and biological signal crosstalk, as described below. The corrected intensities are then passed to a probabilistic model, which ultimately yields a set of four likelihoods of four possible base response outcomes for each DNB. Several metrics were then combined using pre-fitted logistic regression to calculate the base response score. Intensity correction: several sources of biological and optical crosstalk are corrected using linear regression models that are executed as computer logic executed by one or more computing devices. Linear regression outperforms deconvolution methods, which are more computationally expensive and produce results of similar quality. Sources of optical crosstalk include filter band overlap between the four fluorescent dye spectra, and lateral crosstalk between adjacent DNBs due to diffraction of light in their close proximity. Biological sources of crosstalk include incomplete washing of previous cycles, probe synthesis errors and probe 'slips' contaminating adjacent position signals, incomplete anchor extensions when interrogating bases 'outside' (further away from) the anchor. Linear regression is used to determine the fraction of DNB intensities that can be predicted using the intensity of any neighboring DNB or intensities from previous cycles or other DNB locations. Then, the intensity portion, which can be explained by these sources of crosstalk, is subtracted from the initial extracted intensity. To determine the regression coefficients, the intensity on the left side of the linear regression model needs to consist mainly of only the 'background' intensity, i.e., the intensity of DNB that a given base undergoing regression will not respond to. This requires a pre-response (pre-trapping) step using the initial intensity. Once selected without a particular base response (with reasonable confidence) DNB, the computing device or its computer logic implements a simultaneous regression of the crosstalk sources: the neighbor DNB crosstalk is corrected using the regression described above. Also, each DNB is corrected for its particular neighborhood using a linear model involving all neighbors in all available DNB locations. Base response probability: the use of the maximum intensity responsive base does not result in a different shape of the background intensity distribution of the four bases. To account for such possible differences, a probabilistic model is developed based on empirical probability distributions of background intensities. Once the intensities are corrected, the computing device or its computer logic pre-responds with some DNBs of the maximum intensity (DNBs that pass a certain confidence threshold) and uses these pre-responded DNBs to drive the background intensity distribution (the intensity distribution of DNA for which a given base does not respond). After obtaining such a distribution, the computing device may calculate, for each DNB, a tail probability at the distribution that describes an empirical probability that the intensity is the background intensity. Thus, for each DNB and each of the four intensities, the computing device or logic thereof may obtain and store its probability as a backgroundThe computing device may then calculate the probabilities of all possible base responses using these probabilities. Possible base response results need to also describe points that may or may not be occupied by DNBs, either doubly or generally multiply. Combining the computed probabilities with their prior probabilities (lower prior for multiply occupied or empty points) yields probabilities of 16 possible outcomes: These 16 probabilities can then be combined to obtain a reduced set of four probabilities for the four possible base responses. That is to say: and (3) calculating a score: logistic regression is used to derive the score calculation formula. The computing device or its computer logic fits a logistic regression to the localization results of the base response using several metrics as inputs. The metrics include a probability ratio between the responding base and the next highest base, the strength of the responding base, an indicator variable of the identity of the responding base, and a metric describing the overall cluster quality of the domain (field). All metrics translate to a co-linear log-odds-ratio between the harmonious and uncoordinated responses. The model is refined using cross-validation. A logit (logit) function with the final logistic regression coefficients is used to calculate the resulting score. Positioning and assembling In other embodiments, the read data is encoded in compressed binary form and includes both the base and quality scores of the response. The mass score correlates with base accuracy. Analysis software logic, including sequence assembly software, can use the scores to determine the contribution of evidence from individual bases having reads. The read result may be 'jagged' due to the DNB structure. The size of the nicks varies with the variability inherent in enzymatic digestion (usually +/-1 base). Due to the random access nature of cPAL, reads may occasionally have unread bases ('no response') in otherwise high quality DNBs. The pairs of reads are paired. Mapping software logic capable of aligning the read data to a reference sequence can be used to map the data generated by the sequencing methods described herein. Such positioning logic, when executed by one or more computing devices, will generally tolerate small variations relative to a reference sequence, such as those caused by individual genomic variations, read errors, or unread base. This property often allows direct reconstruction of SNPs. To support transposing larger variations, including large-scale structural variations or dense variation regions, each arm of the DNB can be located separately, applying mate (mate) pairing constraints after alignment. As used herein, the term 'sequence variant' or 'variant only' includes any variant, including but not limited to substitution or substitution of one or more bases; insertions or deletions of one or more bases (also known as 'indels'); inverting; transforming; duplication or Copy Number Variation (CNV); trinucleotide repeat expansion; structural changes (SV; e.g., intrachromosomal or interchromosomal rearrangements, e.g., translocations); and so on. In a diploid genome, 'heterozygosity' or 'het' is two different alleles of a particular gene in a gene pair. The two alleles may be different mutants or wild-type alleles paired with mutants. The method may also be used in the analysis of non-diploid organisms, whether such organisms are haploid/monoploid (N-1, where N is the haploid number of chromosomes) or polyploid or aneuploid. In some embodiments, assembly of sequence reads may utilize software logic that supports DNB read structures (paired, gapped reads with non-responsive bases) to generate diploid genomic assemblies, which in some embodiments may be utilized by the sequence information generated for the LFR methods of the invention for phasing heterozygote sites. The method of the invention can be used to reconstruct new segments that are not present in the reference sequence. In some embodiments, an algorithm that utilizes a combination of evidence (bayesian) reasoning and de Bruijin graph-based algorithms may be used. In some embodiments, an empirically corrected statistical model for each data set may be used, allowing all read data to be used without pre-filtering or data trimming. Large scale structural changes (including but not limited to deletions, translocations, etc.) and copy number changes can also be detected by adjusting the paired reads. Phasing LFR data Fig. 3 depicts the main steps in the LFR data phasing. These steps are as follows: (1)graph construction using LFR data: one or more computing devices or their computer logic generate an undirected graph in which vertices represent heterozygous SNPs and edges represent connections between those heterozygous SNPs. The edges are made up of orientation and connection strength. One or more computing devices may store such graphs in storage structures including, but not limited to, files, tables, database records, arrays, lists, vectors, variables, memory and/or processor registers, persistent and/or memory data objects instantiated from object-oriented classes, and any other suitable transient and/or persistent data structures. (2)Graph construction using pairwise data: step 2 is similar to step 1, where the data is concatenated based on the mate as opposed to the LFR data. To perform ligation, DNBs must be found with two heterozygous SNPs of interest in the same read (same arm or partner arm). (3)And (3) combining the drawings:the computing device of each of the above figures, or computer logic representation thereof, is conducted via an NxN sparse matrix, where N is the number of candidate heterozygous SNPs on the chromosome. Two nodes may have only one connection in each of the above methods. In the case of combining two methods, two nodes may have up to two connections. Thus, the computing device or its computer logic may use a selection algorithm to select one connection as the selected connection. For these studies, it was found that the quality of the mate pair data was significantly inferior to the LFR numberAccording to the quality. Thus, only LFR-derived connections are used. (4)And (3) figure trimming:a series of heuristics are designed and applied by the computing device against the stored map data to remove the concatenation of some errors. More precisely, the nodes must satisfy the condition of at least two connections in one direction and one connection in the other direction; otherwise, it is eliminated. (5)Optimizing the graph:the computing device or its computer logic optimizes the graph by generating a Minimum Spanning Tree (MST). The power function is set to-intensity. During this process, lower intensity edges are eliminated, where possible, due to competition with stronger paths. Thus, MST provides a natural choice of the strongest and most reliable connection. (6)Establishing a contig:once the minimum spanning tree is generated and/or stored in the computer readable medium, the computing device or logic thereof may reorient all nodes during which a node (here, the first node) constant is taken. This first node is an anchor node. For each node, the computing device then finds a path to the anchor node. The direction of the test node is the aggregate of the direction of the upper edge of the path. (7)General phasing:after the above steps, the computing device or its logic phases each contig established in the previous step. Here, in contrast to phasing, the results in this section are referred to as pre-phased, indicating that this is not final phasing. Since the first node is arbitrarily chosen as the anchor node, the phasing of the entire contig does not have to be consistent with the parent chromosome. For universal phasing, several heterozygous SNPs on the contig were used for which a three-plex set of information was available. These three-panel heterozygous SNPs are then used to identify alignments of contigs. At the end of the general phasing step, all contigs have been appropriately labeled and can therefore be considered as whole chromosome contigs. Contig generation To generate contigs, the computing device or its computer logic tests two hypotheses for each heterozygous SNP pair: a forward direction and a reverse direction. Forward orientation means that two heterozygous SNPs are joined in the same orientation as they were originally listed (originally alphabetically). The reverse orientation means that two heterozygous SNPs are connected in the reverse order of their original list. Fig. 4 depicts a pairwise analysis of neighboring heterozygous SNPs, which involves grouping forward and reverse directions into heterozygous SNP pairs. Each direction will have numerical support showing the validity of the corresponding hypothesis. This support is a function of the 16 cells of the connection matrix shown in fig. 5, which fig. 5 shows an example of hypothetical selections and assigns scores thereto. To simplify the function, 16 variables are reduced to 3: power 1, power 2, and impurities (impurity). Powers 1 and 2 are the two highest valued cells corresponding to each hypothesis. The impurity is the ratio of the sum of all other cells (not the 2 corresponding to the hypothesis) to the sum of the cells in the matrix. The selection between the two hypotheses is made based on the sum of the corresponding units. The hypothesis with the higher sum is the winning hypothesis. The following calculations are only used to assign the strength of the hypothesis. A strong assumption is the assumption of high values for powers 1 and 2 and low values for impurities. The three measures, power 1, power 2 and impurity, are fed into a fuzzy inference system (fig. 6) to reduce their effect to a single numerical-score between 0 and 1, including the endpoints. A Fuzzy Inference System (FIS) is implemented as computer logic, which may be executed by one or more computing devices. Ligation operations are performed for each heterozygous SNP pair within a reasonable distance up to the expected contig length (e.g., 20-50 Kb). FIG. 6 shows a map construction depicting some exemplary connections and strengths of three neighboring heterozygous SNPs. The rules of the fuzzy inference engine are defined as follows: (1) if the power 1 is small and the power 2 is small, the score is very small. (2) If the power of 1 is medium and the power of 2 is small, the score is small. (3) If the power of 1 is medium and the power of 2 is medium, the score is medium. (4) If the power 1 is large and the power 2 is small, the score is medium. (5) If the power 1 is large and the power 2 is medium, the score is large. (6) If the power 1 is large and the power 2 is large, the score is very large. (7) If the impurity is small, the score is large. (8) If the impurity is moderate, the score is small. (9) If the impurity is large, the score is very small. The definitions of smaller, medium and larger are different for each variable and are determined by its particular membership function. After exposing the Fuzzy Inference System (FIS) to each set of variables, the contribution of the input set to the rules is propagated to the fuzzy logic system and a single (defuzzified) number of outputs is generated: and (6) scoring. This score is limited to between 0 and 1, with 1 showing the highest quality. After applying the FIS to each node pair, the computing device or its computer logic constructs the entire graph. An example of this is shown in figure 7. The nodes are colored according to the direction of the winning hypothesis. The strength of each ligation was derived by applying FIS to the heterozygous SNP of interest. Once the preliminary graph is constructed (top graph of FIG. 7), the computing device or its computer logic optimizes the graph (bottom graph of FIG. 7) and reduces it into a tree. This optimization process is accomplished by generating a Minimum Spanning Tree (MST) from the initial graph. MST guarantees a unique path from each node to any other node. Figure 7 shows graph optimization. In this application, the first node on each contig serves as an anchor node, and all other nodes are oriented with respect to the node. Depending on the orientation, each hit would have to be flipped or otherwise matched to the orientation of the anchor node. FIG. 8 shows the contig alignment method of the given example. At the end of the method, phased contigs are obtained. At this point in the quantification method, the two haplotypes were separated. Although one of these haplotypes is known to be from the template and one from the father, it is completely unknown which one comes from which parent. In the next step of phasing, the computing device or its computer logic attempts to assign the correct parent label (maternal/paternal) to each haplotype. This process is called universal phasing. To do so, it is necessary to know the association of at least several heterozygous SNPs (on the contig) with the parent. This information can be obtained by phasing a three-person group (female parent-male parent-offspring). Using triple sequencing of the genome, some loci with known parental associations are identified, more particularly when at least one parent is homozygous. The computing device or its computer logic then uses these associations to assign the correct parent label (maternal/paternal) to the entire contig, that is, to implement parent-assisted universal phasing (fig. 9). To ensure high accuracy, the following may be implemented: (1) when possible (e.g. in the case of NA 19240), obtain triplet information from multiple sources (e.g. internal and 1000 genomes) and use a combination of such resources; (2) it is desirable that the contig comprises at least two known triple phased loci; (3) elimination of contigs with a series of triple mismatches (indicating sector errors) in one row; and (4) elimination of contigs with a single triplet of mismatches at the end of the triple locus (indicating potential segment errors). Fig. 10 shows natural contig separation. Whether or not the parental data is used, contigs are often not naturally continuous beyond a certain point. The reason for the separation of contigs is: (1) DNA fragmentation or lack of amplification beyond usual in some regions, (2) low heterozygous SNP density, (3) poly-N sequences on the reference genome, and (4) DNA repeats (prone to mislocalization). Fig. 11 shows the general phasing. One of the major advantages of universal phasing is the ability to obtain a complete chromosome 'contig'. This is possible because each contig (after general phasing) carries a haplotype with the correct parent tag. Thus, all contigs carrying the tag parents can be placed on the same haplotype; and similar operations can be performed on the paternal contigs. Another major advantage of the LFR method is the ability to significantly improve the accuracy of the heterozygous SNP response. Fig. 12 shows two examples of error detection resulting from the use of the LFR method. The first example is shown in fig. 12 (left side), where the connection matrix does not support any of the intended assumptions. This indicates that one of the heterozygous SNPs is not actually a heterozygous SNP. In this example, the A/C heterozygous SNP is actually a homozygous locus (A/A), which is tagged as a heterozygous locus by assembler error. This error can be identified and eliminated or (in this case) corrected. A second example is shown in fig. 13 (right side), where the connection matrix of this case supports both of these assumptions. This is an indication that the hybrid SNPerozygous response is not authentic. A 'healthy' heterozygous SNP connection matrix is a connection matrix with only two high units (at the expected heterozygous SNP position, i.e. not in a straight line). All other possibilities point to potential problems and can be eliminated or used to generate an alternating base response to the locus of interest. Another advantage of the LFR approach is the ability to respond to heterozygous SNPs (e.g., where DNB localization is difficult due to preference or mismatch rate) is poorly supported. Since the LFR method requires additional constraints on the heterozygous SNP, the threshold required for the heterozygous SNP response in the non-LFR assembler can be lowered. FIG. 13 shows an example of this situation, where a confident heterozygous SNP response can be made, despite a small number of reads. In fig. 13 (right), under normal conditions, a low number of supportive reads would prevent any assembler from responding confidently to the corresponding heterozygous SNP. However, since the ligation matrix is 'clean,' one can more confidently assign heterozygous SNP responses to these loci. Annotating SNPs in splice sites Introns in the transcribed RNA need to be spliced out before they become mRNA. Information about splicing is embodied within the sequences of these RNAs and is based on identity. Mutations in splice site consensus sequences are responsible for many human diseases (Faustino and Cooper, Genes Dev.17:419-437, 2011). Most splice sites correspond to a simple consensus sequence at fixed positions around the exon. In this regard, a program was developed to annotate splice site mutations. In this procedure, the consensus splice site model (www.life.umd.edu/labs/mount/RNAInfo) was used. For the styles: CAG | G in the 5 'end region of an exon ('|' indicates the start of an exon) and MAG | GTRAG in the 3' end region of the same exon ('|' indicates the end of an exon) were searched. Here, M is { a, C }, and R is { a, G }. In addition, splice consensus positions are classified into two classes: form I, where consistency with the model is 100% needed; and form II, wherein consistency with the model is maintained in greater than 50% of cases. It is speculated that SNP mutations in type I positions cause missed splicing, while SNPs in type II positions only reduce the efficiency of the splicing event. The program logic for annotation of splice site mutations includes two parts. In part I, a file is generated containing the sequence of model positions from the input reference genome. In section 2, SNPs from sequencing projects were compared to these model position sequences and any type I and type II mutations were reported. The program logic was exon centered instead of intron centered (for ease of genome analysis). For a given exon, in its 5' end, we look for a common 'cAGg' (for positions-3, -2, -1, 0.0 meaning the start of the exon). Capital letters mean type I positions and lowercase letters mean type II positions). In the 3' end of the exon, a search was performed for the consensus 'magGTrag' (for the position sequences-3, -2, -1,0,1,2,3, 4). Only exons released by the genome that do not meet these requirements are ignored (about 5% of all cases). These exons fall into other minor species of shared splice sites and are not investigated by the process logic. Any SNPs from the sequenced genome were compared to the model sequences at these genomic positions. Any mismatches in type I will be reported. If the mutation deviates from identity, a mismatch in type II position is reported. The above program logic detects most bad splice site mutations. The reported bad SNPs are clearly problematic. There are many other bad SNPs, however, which cause splicing problems that are not detectable by this procedure. For example, there are many introns within the human genome that do not conform to the above-mentioned identities. Also, branch point mutations in the middle of introns may also cause splicing problems. These splice site mutations have not been reported. The SNPs affecting the Transcription Factor Binding Site (TFBS) were annotated. The JASPAR model was used to look for TFBS from the released human genomic sequence (either building block 36 or building block 37). JASPAR Core is for vertebrates modeled as a matrixA set of 130 TFBS location frequency data (Bryne et al, Nucl. acids Res.36: D102-D106,2008; Sandelin et al, Nucl. acids Res.23: D91-D94,2004). These models are available from JASPAR website (C.), (http:// jaspar.genereg.net/cgi-bin/jaspar_db.plrm＝browse&db＝core&tax _ group ═ vertebrates) download. These models are converted to a Position Weight Matrix (PWM) using the following formula: wi-log 2[ (fi + p Ni1/2)/(Ni + Ni1/2)/p]Wherein: fi is the observed frequency for a particular base at position I; ni is the overall observation at the location; and P is the background frequency of the current nucleotide, which by default is 0.25(bogdan. org. ua/2006/09/11/position-frequency-matrix-to-position-weight-matrix-pfm2pwm. html; Wasserman and Sandelin, Nature Reviews, Genetics 5: P276-287,2004). One specific program, mask (meme.sdsc.edu/meme/master-intro.html), was used to search for TFBS sites on sequence segments within the genome. The program was run to extract TFBS sites in the reference genome. The outline of the steps is as follows: (i) for each gene with mRNA [ -5000,1000, extracted from the genome ]The putative TFBS-containing region, 0 is the mRNA start position. (ii) A mask search of the deduced TFBS-containing sequence was run for all PWM models. (iii) Those hits above a given threshold are selected. (iv) For regions with multiple or overlapping hits, only 1-hits, i.e., hits with the highest mask search score, are selected. By virtue of TFBS model hits from a reference genome generated and/or stored in a suitable computer-readable medium, a computing device or its computer logic can identify SNPs located in the region of hits. These SNPs affect the model, and the hit score varies. The second program was written to calculate such changes in hit scores because the segment containing the SNP was run into the PWM model twice, once for the reference, and second for the segment with SNP substitutions. SNPs that caused a drop in segment hit score beyond 3 were identified as bad SNPs. Selection of genes with two bad SNPs. Genes with bad SNPs were classified into two categories: (1) those that affect transcription; and (2) those that affect the transcription binding site. For the AA sequence impact, the following SNP subclasses were included: (1)nonsense or no terminal mutation. These mutations result in truncated or extended proteins. In either case, the function of the protein product is completely lost or less effective. (2)Variation of splice sites. These mutations cause the splice sites of introns to be either disrupted (for those positions where 100% of a certain nucleotide is required according to the model) or severely reduced (for those positions where more than 50% of a certain nucleotide is required according to the model. SNPs cause a splice site nucleotide to be mutated to another nucleotide with less than 50% identity, as predicted by the splice site consensus model). These mutations may result in proteins that are truncated, lack exons, or have severely reduced amounts of protein product. (3)Polyphen2 notes on AA variants. For SNPs that cause changes in the amino acid sequence of a protein, but not in its length, Polyphen2(Adzhubei et al, nat. methods 7:248-249,2010) was used as the primary annotation tool. Polyphen2 annotated SNPs as 'benign', 'unknown', 'potentially damaging', and 'presumably damaging'. Both 'potentially damaging' and 'presumably damaging' were identified as bad SNPs. These species assignments for Polyphen2 are based on structural predictions for the Polyphen2 software. For transcription binding site mutations, a model maximum score (maxsore) of 75% was used based on the reference genome screening as TFBS binding site. Any model hits in the region that < 75% of the maximum score are removed. For those remaining hits, if the SNP causes a drop in hit score by more than 3, it is considered a detrimental SNP. Two classes of genes have been reported. Class 1 genes are those genes that have at least 2 bad AA-affecting mutations. These mutations can be all on a single allele (class 1.1), or spread across 2 unique alleles (class 1.2). Class 2 genes are a superset of the class 1 set. Class 2 genes are genes containing at least 2 bad SNPs, whether it is AA-or TFBS site-influencing. However, it is required that at least 1 SNP is AA-influencing. Class 2 genes are those in class 1, or those with 1 deleterious AA mutation and 1 or more deleterious TFBS-affecting variations. Class 2.1 means that all these deleterious mutations are from a single allele, while class 2.2 means that the deleterious SNPs are from two distinct alleles. The foregoing techniques and algorithms are applicable to methods for sequencing complex nucleic acids, optionally in conjunction with LFR processing prior to sequencing (LFR combined with sequencing may be referred to as 'LFR sequencing'), as described in detail below. Such methods for sequencing complex nucleic acids may be implemented by one or more computing devices executing computer logic. One example of such logic is software code written in any suitable programming language, such as Java, C + +, Perl, Python, and any other suitable conventional and/or object-oriented programming language. When executed in one or more computer processes, such logic may read results, write, and/or otherwise process structured and unstructured data, which may be stored in multiple structures on persistent and/or volatile memory; examples of such storage structures include, but are not limited to, files, tables, database records, arrays, lists, vectors, arguments, memory and/or processor registers, persistent and/or memory data objects instantiated from object-oriented classes, and any other suitable data structures. Improving accuracy in sequencing long reads In DNA sequencing using certain long read techniques (e.g., nanopore sequencing), long (e.g., 10-100kb) read lengths are available, but generally have a higher rate of false negatives and false positives. The ultimate accuracy of sequences from such long read techniques can be significantly enhanced using haplotype information (fully or partially phased) according to the following general method. First, the computing device or its computer logic compares the readings to each other. A large number of heterozygous responses are expected to be present in the overlap. For example, if 2 to 5 100kb fragments overlap by a minimum of 10%, this results in an overlap of >10kb, which can roughly translate into 10 heterozygous loci. Alternatively, each long read is aligned to a reference genome, by which multiple alignments of reads are implied. Once multiple read alignments are achieved, the overlap regions can be considered. The reality that overlap will include a large number (e.g., N-10) of heterozygous loci can be modulated to account for heterozygous combinations. This combination results in a larger space of haplotype probabilities (4N or 4^ 4)N(ii) a If N is 10, then 4NAbout 100 ten thousand). All these 4 in the N-dimensional space NOf the points, only two points are expected to contain biologically viable information, i.e., those corresponding to two haplotypes. In other words, there is 4NA noise suppression ratio of/2 (here 1e6/2 or about 500,000). In practice, most of this 4NSpace is degenerate, especially because the sequences have been aligned (and therefore similar), and also because each locus does not usually carry more than 2 possible bases (if it is truly heterozygous). Thus, the lower bound of this space is effectively 2N(if N is 10, then 2)NAbout 1000). Thus, the noise suppression ratio may be only 2NAnd/2 (here 1000/2 ═ 500), which is still quite impressive. As the number of false positives and false negatives increases, the size of the space is from 2NExpansion to 4NWhich in turn results in a higher noise suppression rate. In other words, as the noise increases, it is automatically more suppressed. Thus, the expected output product retains only a very small (and fairly constant) amount of noise, with little dependence on the input noise. (trade-off is yield loss in more noisy conditions). Of course, these inhibition rates were changed in the following cases: (1) errors are systematic (or other data traits), (2) algorithms are not optimal, (3) overlapping parts are shorter, or (4) overlay redundancy is smaller. N may be any integer greater than 1, such as 2,3,5,10, or more. The following methods may be used to improve the accuracy of long read sequencing methods, which may have a large initial error rate. First, the computing device or its computer logic compares several reads, e.g., 5 reads or more, such as 10-20 reads. Assume that reads are about 100kb and that the shared overlap is 10%, which results in a10 kb overlap out of 5 reads. Heterozygosity was also assumed in every 1 kb. Thus, there would be a total of 10 heterozygosity in this common region. Next, the computing device or its computer logic fills out a portion (e.g., only non-zero elements) or the entire matrix of the alpha10 possibilities for the 10 candidate heterozygosity described above, where alpha is between 2 and 4. In one implementation, only 2 of the alpha10 cells of this matrix should be high density (e.g., as measured by a threshold, which may be predetermined or dynamic). These are units corresponding to true heterozygosity. These two units can be considered as substantially noiseless centers. The remainder should contain almost 0 and occasionally 1 membership, especially if the error is not systematic. If the error is systematic, there may be a clustering event (e.g., with a third element exceeding only 0 or 1) that makes the task more difficult. However, even in this case, the cluster membership of the dummy cluster should be significantly weaker (e.g., as measured by absolute or relative amounts) than the cluster membership of the two expected clusters. The trade-off in this case is that the starting point should include more multiple sequences aligned, which is directly related to having longer reads or greater redundancy of coverage. The above steps assume that two feasible clusters are observed between overlapping reads. This is not the case for a large number of false positives. If this is the case, in the alpha dimension space, the two clusters that are expected will be blurred, i.e. instead of being a single point with a high density, they will be blurred clusters of M points around the cell of interest, where these cells of interest are the noise-free centers in the center of the clusters. This enables the clustering method to capture the location of the expected point despite the fact that the exact sequence is not present in each read. Cluster events may also occur when clusters are ambiguous (i.e., there may be more than two centers), but in a manner similar to that described above, for diploid organisms, a score (e.g., total count of cluster units) may be used to distinguish weaker clusters from two true clusters. Two real clusters can be used to create contigs for multiple regions, as described herein, and contigs can be matched into two groups to form haplotypes for larger regions of complex nucleic acids. Finally, the computing device or its computer logic may use the population-based (known) haplotypes to improve confidence and/or provide additional guidance in finding real clusters. One way to implement this is to provide a weight for each observed haplotype and provide a smaller but non-zero value for the unobserved haplotypes. By doing so, a preference for the native haplotype that has been observed in the population of interest is achieved. Read results using tag sequence data with uncorrected errors As discussed herein, according to one embodiment of the invention, a sample of complex nucleic acids is divided into multiple aliquots (e.g., wells in a multi-well plate), amplified, and fragmented. The aliquot-specific tags are then ligated to the fragments to identify the aliquot from which a particular fragment of the complex nucleic acid originates. Optionally, the tag contains an error correction code, such as a Reed-Solomon error correction (or error detection) code. In sequencing fragments, both the tag and the fragment of the complex nucleic acid sequence are sequenced. If there are errors in the tag sequence and it is not possible to identify the aliquot from which the fragment originated, or to correct the sequence using an error correction code, the entire read can be discarded, resulting in the loss of a large amount of sequence data. It should be noted that reads containing correct and corrected tag sequence data are of high accuracy, but low yield, while reads containing uncorrectable tag sequence data are of low accuracy, but high yield. Instead, such sequence data is used in a different way than those methods that require such data to identify the originating aliquot by virtue of the association of a particular tag with a particular aliquot. Examples of methods that require reads with correct (or corrected) tag sequence data include, but are not limited to, sample or library multiplexing, phasing or error correction, or any other method that requires a correct (or corrected) tag sequence. Examples of methods that can employ reads with tag sequence data that cannot be corrected include any other method, including but not limited to localization, reference-based and local reassembly, set-based statistics (e.g., allele frequencies, location of re-mutations, etc.). Converting long reads to virtual LFR Algorithms designed for LFR, including phasing algorithms, can be used for long reads by attributing random dummy tags (with uniform distribution) to each (10-100kb) long fragment. Virtual tags have the benefit of enabling a truly uniform distribution for each code. LFR cannot achieve this level of consistency due to the difference in merging codes and the difference in decoding efficiency of codes. A 3:1 (and up to 10:1) ratio can be easily observed in the representation of any two codes in the LFR. However, the virtual LFR method results in a true 1:1 ratio between any two codes. Method for sequencing complex nucleic acids SUMMARY In accordance with one aspect of the present invention, a method for sequencing complex nucleic acids is provided. In accordance with certain embodiments of the present invention, methods are provided for sequencing very small amounts of such complex nucleic acids (e.g., 1pg to 10 ng). Even after amplification, such methods produce an assembled sequence characterized by high response rate and accuracy. According to other embodiments, aliquots are used to identify and eliminate errors in complex nucleic acid sequencing. According to another embodiment, the LFR is used in conjunction with complex nucleic acid sequencing. The practice of the present invention may employ, unless otherwise indicated, conventional techniques and descriptions of organic chemistry, polymer technology, molecular biology (including recombinant techniques), cell biology, biochemistry, and immunology, which are within the skill of the art. Such conventional techniques include polymer array synthesis, hybridization, ligation, and detection of hybridization using labels. Specific illustrations of suitable techniques can be had by reference to the following examples. However, other equivalent conventional methods may of course be used. Such conventional techniques and descriptions can be found in standard Laboratory manuals such as Genome Analysis: A Laboratory Manual Series (Vols. I-IV), Using Antibodies: A Laboratory Manual, Cells: A Laboratory Manual, PCR Primer: A Laboratory Manual, and Molecular Cloning: A Laboratory Manual (all from Cold Spring Harbor Laboratory Press), Stryer, L. (1995) Biochemistry (4th Ed.) Free, New York, Gaster, 'Oligonucleotide Synthesis: A Practical Applacard' 1984, IRL Press, Londom Coman, New lson (2000), Lehnger, Principles of Biochemistry, research 3, plant, W.2002, all of which are incorporated by reference, for all purposes. General methods for sequencing target nucleic acids using the compositions and methods of the invention are described herein and for example in U.S. patent publication 2010/0105052 and US2007099208 and U.S. patent application No.11/679,124 (published as US 2009/0264299); 11/981,761(US 2009/0155781); 11/981,661(US 2009/0005252); 11/981,605(US 2009/0011943); 11/981,793(US 2009) -0118488; 11/451,691(US 2007/0099208); 11/981,607(US 2008/0234136); 11/981,767(US 2009/0137404); 11/982,467(US 2009/0137414); 11/451,692(US 2007/0072208); 11/541,225(US 2010/0081128; 11/927,356(US 2008/0318796); 11/927,388(US 2009/0143235); 11/938,096(US 2008/0213771); 11/938,106(US 2008/0171331); 10/547,214(US 2007/0037152); 11/981,730(US 2009/0005259); 11/981,685(US 2009/0036316); 11/981,797(US 2009/0011416); 11/934,695(US 2009/0075343); 11/934,697(US 2009/0111705); 11/934,703(US 2009/0111706); 12/265,593(US 2009/0203551); 11/938,213(US 2009/0105961); 11/938,221(US 2008/0221832); 12/325,922(US 2009/0318304); 12/252,280(US 2009/0111115); 12/266,385(US 2009/0176652); 12/335,168(US 2009/0311691); 12/335,188(US 2008/0318796); 12/335,188) (US 2009/0176234); 12/361,507(US 2009/0263802),11/981,804(US 2011/0004413); and 12/329,365; published international patent application numbers WO2007120208, WO2006073504 and WO2007133831, all of which are incorporated herein by reference in their entirety for all purposes. Exemplary methods for responding to variations in polynucleotide sequences compared to reference polynucleotide sequences and for polynucleotide sequence assembly (or reassembling) are provided, for example, in U.S. patent publication No.2011-0004413, (app No.12/770,089), which is incorporated herein by reference in its entirety for all purposes. Also seen is Drmanac et al, Science 327,78-81,2010. Also incorporated by reference in its entirety And for all purposes is co-pending related application Nos.61/623,876 entitled 'Identification Of Dna Fragments And Structural Variations'. The method includes extracting and fragmenting a target nucleic acid from a sample. Fragmented nucleic acids are used to generate a target nucleic acid template, which will typically comprise one or more adaptors. The target nucleic acid template is subjected to an amplification process to form nucleic acid nanospheres, which are typically disposed on a surface. Sequencing applications are performed on the nucleic acid nanospheres of the present invention, typically via sequencing by ligation techniques, including combinatorial probe-anchored ligation ('cPAL') methods, which are described in more detail below. cPAL and other sequencing methods can also be used to detect specific sequences, such as single nucleotide polymorphisms ('SNPs') including in the nucleic acid constructs of the invention, including nucleic acid nanospheres and linear and circular nucleic acid templates. The above-mentioned patent applications and the articles cited by Drmanac et al provide additional details regarding: for example, preparing a nucleic acid template, including adaptor design, inserting adaptors into genomic DNA fragments to generate circular library constructs; amplifying such library constructs to generate DNA Nanospheres (DNBs); generating an array of DNBs on a solid support; sequencing by cPAL; and the like, which are used in conjunction with the methods disclosed herein. As used herein, the term 'complex nucleic acid' refers to a large population of different nucleic acids or polynucleotides. In certain embodiments, the target nucleic acid is genomic DNA; exome DNA (a subset of whole genome DNA enriched for transcribed sequences that contains a collection of exons in the genome); transcriptome (i.e., the collection of all mRNA transcripts produced in a cell or population of cells, or cDNA produced from such mrnas), methylation set (methyl) (i.e., the population of methylation sites and methylation patterns in the genome); microbiome (microbiome); a mixture of genomes of different organisms, a mixture of genomes of different cell types of an organism; and other complex nucleic acid mixtures comprising a large number of different nucleic acid molecules (examples include, but are not limited to, microbiome, xenograft, solid tumor biopsy including both normal and tumor cells, and the like), including subsets of the aforementioned types of complex nucleic acids. In one embodiment, such complex nucleic acids have an entire sequence comprising at least one gigabase (Gb) (a diploid human genome comprises about 6Gb sequences). Non-limiting examples of complex nucleic acids include 'circulating nucleic acids' (CNAs), which are nucleic acids that circulate in human blood or other bodily fluids (e.g., including, but not limited to, lymph, fluids, ascites, milk, urine, feces, and bronchial lavage) and can be distinguished as cell-free (CF) or cell-associated nucleic acids (reviewed in pinzania et al, Methods 50: 302-. Another example is a single cell or a small number of cells, such as, for example, genomic DNA of a small number of cells from a biopsy (e.g., fetal cells from a blastocyst trophectoderm biopsy; cancer cells from a needle aspiration of a solid tumor; etc.). Another example is pathogens in tissues, blood or other body fluids, such as bacterial cells, viruses or other pathogens, etc. As used herein, the term 'target nucleic acid' (or polynucleotide) or 'nucleic acid of interest' refers to any nucleic acid (or polynucleotide) suitable for processing and sequencing by the methods described herein. The nucleic acid may be single-stranded or double-stranded, and may comprise DNA, RNA, or other known nucleic acids. The target nucleic acids may be those of any organism including, but not limited to, viruses, bacteria, yeast, plants, fish, reptiles, amphibians, birds, and mammals (including, but not limited to, mice, rats, dogs, cats, goats, sheep, cows, horses, pigs, rabbits, monkeys, and other non-human primates and humans). The target nucleic acid can be obtained from an individual or a plurality of individuals (i.e., a population). The sample from which the nucleic acid is obtained may contain nucleic acids from a mixture of cells or even organisms, such as: a human saliva sample comprising human cells and bacterial cells; a mouse xenograft comprising mouse cells and cells from a transplanted human tumor; and so on. The target nucleic acid may be unamplified or may be amplified by any suitable nucleic acid amplification method known in the art. The target nucleic acids can be purified according to methods known in the art to remove cellular and subcellular impurities (lipids, proteins, carbohydrates, nucleic acids different from those to be sequenced, etc.), or they can be unpurified, i.e., include at least some cellular and subcellular impurities, including but not limited to intact cells that have been disrupted to release their nucleic acids for processing and sequencing. The target nucleic acid can be obtained from any suitable sample using methods known in the art. Such samples include, but are not limited to: tissues, isolated cells or cell cultures, bodily fluids (including but not limited to blood, urine, serum, lymph, saliva, anal and vaginal secretions, perspiration, and semen); air, agriculture, water and soil samples, and the like. In one aspect, the nucleic acid construct of the invention is formed from genomic DNA. High coverage of shotgun sequencing is desirable because it can overcome errors in base response and assembly. As used herein, for any given position in an assembled sequence (assembled sequence), the terms 'sequence cover redundant', 'sequence cover' or simply 'cover' mean the number of reads representing the position. It can be calculated as NxL/G from the length of the initial genome (G), the number of reads (N), and the average read length (L). Coverage can also be directly calculated by counting the bases at each reference position. For whole genome sequences, coverage is expressed as the average of all bases in the assembled sequence. Sequence coverage is the average number of times a base is read (as described above). It is often expressed in 'fold coverage', e.g., '40 fold coverage', meaning that each base is represented by an average of 40 reads in the final assembled sequence. As used herein, the term 'response rate' means a comparison of the percentage of bases in a complex nucleic acid that are fully responsive, typically with reference to a suitable reference sequence, such as, for example, a reference genome. Thus, for a fully human genome, the 'genome response rate' (or simply 'response rate') is the percentage of bases in the human genome that respond completely relative to a fully human genome reference. 'exome response rate' is the percentage of bases in an exome that respond completely relative to an exome reference. Exome sequences can be obtained by sequencing portions of the genome enriched using a variety of known methods for selectively capturing genomic regions of interest from a DNA sample. Alternatively, exome sequences can be obtained by sequencing a whole human genome that includes exome sequences. As such, a fully human genomic sequence may have both a 'genomic response rate' and an 'exome response rate'. There is also the 'raw read response rate' which reflects the number of bases assigned A/C/G/T, rather than the total number of bases tried. (occasionally, the term 'overlay' is used in place of 'response rate,' but the meaning will be apparent from context). Preparation of fragments of Complex nucleic acids And (3) separating nucleic acid. The target genomic DNA is isolated using conventional techniques, for example as disclosed in Sambrook and Russell, Molecular Cloning: A Laboratory Manual, cited above. In some cases, especially if small amounts of DNA are employed in a particular step, it is advantageous to provide carrier DNA, e.g.unrelated circular synthetic double stranded DNA, to be mixed and used with the sample DNA whenever only small amounts of sample DNA are available and the risk of loss through e.g.non-specific binding to the container walls etc. is lost. According to some embodiments of the invention, genomic DNA or other complex nucleic acids are obtained from a single cell or a small number of cells with or without purification. Long segments are desirable for LFR. Long fragments of genomic nucleic acid can be isolated from cells by a number of different methods. In one embodiment, the cells are lysed and the intact nuclei are pelleted with a gentle centrifugation step. Genomic DNA is then released via proteinase K and rnase digestion for several hours. The material may be treated to reduce the concentration of residual cellular waste, for example by dialysis for a period of time (i.e. 2-16 hours) and/or dilution. Since such methods do not require the use of many destructive methods (such as ethanol precipitation, centrifugation, and vortexing), the genomic nucleic acid remains largely intact, producing most fragments with a length in excess of 150 kilobases. In some embodiments, the fragments are about 5 to about 750 kilobases in length. In other embodiments, fragments are from about 150 to about 600, from about 200 to about 500, from about 250 to about 400, and from about 300 to about 350 kilobases in length. The smallest fragment that can be used in an LFR is a fragment containing at least two heterozygosity (about 2-5kb) and has no maximum theoretical size, although the fragment length can be limited due to cleavage resulting from the manipulation of the starting nucleic acid preparation. Techniques that produce larger fragments result in fewer aliquots being required, and those that produce shorter fragments may require more aliquots. Once the DNA is isolated and before it is aliquoted into individual wells, it is fragmented carefully to avoid loss of material, particularly sequences from the end of each fragment, as loss of such material can lead to gaps in final genome assembly. In one embodiment, sequence loss is avoided by using rare nicking enzymes that create the start sites for polymerases such as phi29 polymerase at a distance of about 100kb from each other. As the polymerase creates a new DNA strand, it displaces the old strand, which creates an overlapping sequence near the polymerase start site. Thus, there are very few sequence deletions. The controlled use of 5' exonucleases (before or during amplification, e.g., by MDA) can facilitate multiple replications of initial DNA from single cells, thus minimizing the growth of early errors via copy replication. In other embodiments, long DNA fragments are isolated and manipulated in a manner that minimizes shearing or adsorption of DNA to the container, including, for example, separating cells in agarose or oil in agarose gel plugs, or using specially coated tubes and plates. In some embodiments, further replication of fragmented DNA from single cells prior to aliquot sampling may be achieved by ligating adaptors to single stranded priming protrusions and using adaptor specific primers and phi29 polymerase to generate two copies from each long fragment. This can generate DNA equivalent to 4 cells from a single cell. And (4) fragmenting. The target genomic DNA is then fractionated or fragmented to the desired size by conventional techniques including enzymatic digestion, shearing or sonication, the latter two of which are particularly useful in the present invention. The fragment size of a target nucleic acid may vary with the source target nucleic acid and the library construction method used, but for standard whole genome sequencing, such fragments typically range from 50 to 600 nucleotides in length. In another embodiment, the fragment is 300 to 600 or 200 to 2000 nucleotides in length. In yet another embodiment, the length of the fragment is 10-100,50-100,50-300,100-200,200-300,50-400,100-400,200-400,300-400, 400-400, 500-500, 500-600,50-1000,100-1000,200-1000,300-1000,400-1000,500-1000,600-1000, 700-900,700-800, 800-800, 900-1000,1500-2000,1750-2000 and 50-2000 nucleotides. Longer fragments may be used for LFR. In other embodiments, fragments of a particular size or in a particular size range are isolated. Such methods are well known in the art. For example, gel fractionation can be used to generate a population of fragments of a particular size within a range of base pairs, e.g., for 500 base pairs +50 base pairs. In many cases, enzymatic digestion of the extracted DNA is not required, as the shear forces generated during lysis and extraction will generate fragments in the desired range. In other embodiments, shorter fragments (1-5kb) may be generated by enzymatic fragmentation using restriction endonucleases. In yet another embodiment, about 10 to about 1,000,000 genome equivalents (equivalents) of DNA ensure that the population of fragments covers the entire genome. Libraries containing nucleic acid templates generated from such populations of overlapping fragments will thus contain target nucleic acids whose sequences, once identified and assembled, will provide most or the entire sequence of the entire genome. In some embodiments of the invention, fragments are prepared using a controlled random enzymatic ('CoRE') fragmentation method. CoRE fragmentation is an enzymatic end-point assay and has the advantages of enzymatic fragmentation (such as the ability to use it with lower amounts and/or volumes of DNA) without its many disadvantages (including sensitivity to changes in substrate or enzyme concentration and sensitivity to digestion time). In one aspect, the present invention provides a fragmentation process referred to herein as controlled random enzymatic (CoRE) fragmentation, which can be used alone or in combination with other mechanical and enzymatic fragmentation processes known in the art. CoRE fragmentation involves a series of three enzymatic steps. First, the nucleic acid is subjected to an amplification process which is carried out in the presence of dNTPs spiked with a proportion of deoxyuracil ('dU') or uracil ('U') to result in dUTP or UTP substitution at a defined and controllable proportion of the T positions in both strands of the amplification product. Any suitable amplification method may be used in this step of the invention. In certain embodiments, Multiple Displacement Amplification (MDA) in the presence of dntps spiked with dUTP or UTP at a defined ratio to dTTP is used to generate amplification products with dUTP or UTP substituted into certain points on both strands. Following amplification and uracil module insertion, uracil is then cleaved, typically via a combination of UDG, EndoVIII, and T4PNK, to create a single base gap with a functional 5 'phosphate and 3' hydroxyl terminus. Single base gaps will be created at average intervals defined by the U frequency in the MDA product. That is, the higher the amount of dUTP, the shorter the resulting fragment. As will be appreciated by those skilled in the art, other techniques that will result in selective replacement of a nucleotide with a modified nucleotide that can similarly produce cleavage can also be used, such as chemically or other enzymatically susceptible nucleotides. Treatment of the nicked nucleic acid with a polymerase having exonuclease activity causes nicks to 'translate' or 'shift' along the length of the nucleic acid until the nicks on opposite strands converge, thereby creating double-stranded breaks, which produce a relative population of double-stranded fragments of relatively homogeneous size. The exonuclease activity of a polymerase, such as Taq polymerase, will cleave short DNA strands close to the nick, whereas the polymerase activity will 'fill in' the nick and subsequently the nucleotides in the strand (indeed, Taq moves along the strand, excising a base using exonuclease activity and adding the same base, with the result that the nick shifts along the strand until the enzyme reaches the end). Since the size distribution of the double-stranded fragments is a result of the ratio of dTTP to dUTP or UTP used in the MDA reaction, and not due to the duration or degree of enzymatic treatment, this method of coce fragmentation yields a high degree of reproducibility of fragmentation, which generates a population of double-stranded nucleic acid fragments that are all of similar size. Fragment end repair and modification. In certain embodiments, after fragmentation, the target nucleic acids are further modified to make them ready for insertion of multiple adaptors according to the methods of the present invention. After physical fragmentation, the target nucleic acid typically has a combination of blunt-ended and overhanging ends and a combination of terminal phosphate and hydroxyl chemistry. In this embodiment, the target nucleic acid is treated with several enzymes to create blunt ends with a specific chemistry. In one embodiment, a polymerase and dntps are used to fill any 5' single strands of the overhang to create a blunt end. A polymerase having 3 ' exonuclease activity (typically but not always the same enzyme as the 5 ' active enzyme, such as T4 polymerase) is used to remove the 3 ' protrusions. Suitable polymerases include, but are not limited to, T4 polymerase, Taq polymerase, e.coli DNA polymerase 1, Klenow fragment, reverse transcriptase, phi29 related polymerases including wild-type phi29 polymerase and derivatives of such polymerases, T7DNA polymerase, T5 DNA polymerase, RNA polymerase. These techniques can be used to generate blunt ends, which can be used in a variety of applications. In other optional embodiments, the terminal chemistry is altered to avoid linking the target nucleic acids to each other. For example, in addition to polymerases, protein kinases can also be used in the process of creating blunt ends by converting a 3 'phosphate group to a hydroxyl group using its 3' phosphatase activity. Such kinases may include, but are not limited to, commercially available kinases such as T4 kinase, and non-commercially available kinases but with the desired activity. Similarly, phosphatases can be used to convert terminal phosphate groups to hydroxyl groups. Suitable phosphatases include, but are not limited to, alkaline phosphatase (including calf intestinal phosphatase), antarctic phosphatase, apyrase, pyrophosphatase, inorganic (yeast) thermostable inorganic pyrophosphatase, and the like, as are known in the art. These modifications prevent the target nucleic acids from ligating to each other in subsequent steps of the methods of the invention, thus ensuring that during the step of ligating the adaptors (and/or adaptor arms) to the ends of the target nucleic acids, the target nucleic acids will be ligated to adaptors but not to other target nucleic acids. The target nucleic acid can be ligated to the adaptor in a desired orientation. Modifying the ends avoids unwanted configurations in which the target nucleic acids are ligated to each other and/or adaptors are ligated to each other. The direction of each adaptor-target nucleic acid ligation can also be controlled via control of the end chemistry of both the adaptor and the target nucleic acid. Such modifications can prevent the creation of nucleic acid templates containing different fragments joined in unknown configurations, thus reducing and/or eliminating errors in sequence identification and assembly that can result from such unwanted templates. DNA may be denatured after fragmentation to generate single-stranded fragments. And (5) amplification. In one embodiment, after fragmentation (and indeed before or after any of the steps outlined herein), an amplification step may be applied to the fragmented nucleic acid population to ensure that a sufficiently large concentration of all fragments is available for subsequent steps. In accordance with one embodiment of the present invention, a method is provided for sequencing small amounts of complex nucleic acids, including those of higher organisms, wherein such complex nucleic acids are amplified to generate sufficient nucleic acids for sequencing by the methods described herein. The sequencing methods described herein provide high accuracy sequences with high response rates with sufficient amplification, i.e., using one gene equivalent as the starting material. Note that the cells contained approximately 6.6 picograms (pg) of genomic DNA. Whole genomes or other complex nucleic acids from a single cell or a small number of cells of an organism, including higher organisms such as humans, can be performed by the methods of the invention. Sequencing of complex nucleic acids of higher organisms can be achieved using 1pg,5pg,10pg,30pg,50pg,100pg or 1ng of complex nucleic acid as starting material, which is amplified by any nucleic acid amplification method known in the art to generate, for example, 200ng,400ng,600ng,800ng,1 μ g,2 μ g,3 μ g,4 μ g,5 μ g,10 μ g or greater quantities of complex nucleic acid. We also disclose nucleic acid amplification protocols that minimize GC bias. However, the need for expansion and subsequent GC preference can be further reduced by isolating only one cell or a small number of cells, culturing them under suitable culture conditions known in the art for a sufficient time, and sequencing using progeny of one or more of the starting cells. Such amplification methods include, but are not limited to: multiple Displacement Amplification (MDA), Polymerase Chain Reaction (PCR), ligation chain reaction (sometimes referred to as oligonucleotide ligase amplification OLA), Cycling Probe Technology (CPT), Strand Displacement Assay (SDA), transcription-mediated amplification (TMA), nucleic acid sequence-based amplification (NASBA), Rolling Circle Amplification (RCA) (for circularized fragments), and invasive cleavage techniques. Amplification may be performed after fragmentation or before or after any of the steps outlined herein. MDA amplification protocol with reduced GC preference. In one aspect, the invention provides a method of preparing a sample in which about 10Mb of DNA per aliquot is faithfully amplified, e.g., about 30,000 fold based on the starting amount of DNA, prior to library construction and sequencing. According to one embodiment of the LFR method of the invention, the LFR starts with treatment of genomic nucleic acid, typically genomic DNA, with a 5 'exonuclease to create 3' single stranded protrusions. Such single-stranded overhangs serve as MDA initiation sites. The use of exonucleases also eliminates the need for a thermal or alkaline denaturation step prior to amplification and introduces no preference for the population of fragments. In another embodiment, alkali denaturation is combined with 5' exonuclease treatment, which results in a reduction in preference greater than that seen with either treatment alone. The DNA treated with 5' exonuclease and optionally alkali denaturation is then diluted to subgenomic concentrations and dispersed among multiple aliquots as discussed above. After dividing into aliquots, for example between a plurality of wells, the fragments in each aliquot are amplified. In one embodiment, phi 29-based Multiple Displacement Amplification (MDA) is used. Many studies have examined the scope of unwanted amplification preferences, background product formation and chimeric artefacts introduced via phi 29-based MDA, but many of these disadvantages have occurred under extreme amplification conditions (greater than 100 ten thousand fold). Typically, LFRs employ substantially lower amplification levels and start with long DNA fragments (e.g., about 100kb), which results in efficient MDA and more acceptable levels of amplification preference and other amplification related problems. We have developed improved MDA protocols to overcome the problems associated with MDA using various additives (e.g., DNA modifying enzymes, sugars and/or chemicals, such as DMSO) and/or to reduce, increase or replace different components of the MDA reaction conditions to further improve the protocols. To minimize chimerism, agents may also be included to reduce the availability of displaced single-stranded DNA that acts as an incorrect template for an extended DNA strand (which is a common mechanism of chimerism formation). The main source of overlay preference introduced by MDA is due to the amplification difference between GC-rich versus AT-rich regions. This can be corrected for by using different reagents in the MDA reaction and/or by adjusting primer concentrations to create an environment that primes uniformly across all% GC regions of the genome. In some embodiments, random hexamers are used in priming the MDA. In other embodiments, other primer designs are utilized to reduce preference. In other embodiments, the use of 5' exonucleases before or during MDA can help to initiate low preference successful priming, particularly with longer (i.e., 200kb to 1Mb) fragments that can be used to sequence regions characterized by long segment replication (i.e., in some cancer cells) and complex repeats. In some embodiments, improved, more efficient fragmentation and ligation steps are used, which reduce the number of rounds of MDA amplification required to prepare a sample by up to 10,000-fold, which further reduces the preference for and chimera formation from MDA. In some embodiments, the MDA reaction is designed to introduce uracil into the amplification product in preparation for the coce fragmentation. In some embodiments, a standard MDA reaction using random hexamers is used to amplify the fragments in each well; alternatively, random 8-mer primers can be used to reduce amplification preferences (e.g., GC preferences) in a population of fragments. In other embodiments, several different enzymes may also be added to the MDA reaction to reduce amplification preference. For example, low concentrations of non-processive 5' exonucleases and/or single-stranded binding proteins can be used to create 8-mer binding sites. Chemical agents such as betaine, DMSO, and trehalose may also be used to reduce preferences. After amplification of the fragments in each aliquot, the amplification products may optionally be subjected to another round of fragmentation. In some embodiments, the CoRE method is used to further fragment the fragments in each aliquot after amplification. In such embodiments, the MDA amplification of the fragments in each aliquot is calculated to incorporate uracil into the MDA product. Each aliquot containing MDA product was treated with a mixture of Uracil DNA Glycosylase (UDG), DNA glycosylase-lyase endonuclease VIII and T4 polynucleotide kinase to excise the uracil base and create a single base gap with a functional 5 'phosphate and 3' hydroxyl group. Nick translation via the use of a polymerase such as Taq polymerase results in double-stranded blunt end breaks, which generate ligatable fragments in a size range that depends on the concentration of dUTP added in the MDA reaction. In some embodiments, the CoRE method used involves removal of uracil by phi29 polymerization and strand displacement. Fragmentation of the MDA product can also be achieved via sonication or enzymatic treatment. Enzymatic treatments that may be used in this embodiment include, but are not limited to, DNase I, T7 Endonuclease I, Micrococcus nuclease, and the like. After fragmentation of the MDA product, the ends of the resulting fragments can be repaired. Many fragmentation techniques can generate termini with overhangs and termini with functional groups that are not available for subsequent ligation reactions, such as 3 'and 5' hydroxyl groups and/or 3 'and 5' phosphate groups. It may be useful to have fragments repaired to have blunt ends. It may also be desirable to modify the termini to add or remove phosphate and hydroxyl groups to prevent 'polymerization' of the target sequence. For example, phosphatases can be used to eliminate phosphate groups such that all termini contain hydroxyl groups. Each end can then be selectively altered to allow for the linkage between the desired components. One end of the 'activated' fragment can then be treated with alkaline phosphatase. The fragments can then be tagged with adaptors to identify fragments from the same aliquot in the LFR method. The fragments in each aliquot were labeled. Following amplification, the DNA in each aliquot is tagged, thereby identifying the aliquot from which each fragment originated. In other embodiments, the amplified DNA in each aliquot may be further fragmented prior to tagging with adaptors, such that fragments from the same aliquot will all comprise the same tag; see, for example, US 2007/0072208, which is incorporated herein by reference. According to one embodiment, the adaptors are designed in two segments: one segment is common to all wells and the blunt ends directly link the fragments using methods described further herein. The 'common' adaptor is added as two adaptor arms: one arm is a blunt end attached to the 5 'end of the fragment, and the other arm is a blunt end attached to the 3' end of the fragment. The second segment of the tagged adapter is a 'barcode' segment that is unique to each well. This barcode is typically a unique nucleotide sequence and each fragment in a particular well is given the same barcode. As such, when tagged fragments from all wells are recombined for sequencing applications, fragments from the same well can be identified via identification of barcode adaptors. The barcode was ligated to the 5' end of the common adapter arm. Common adaptors and barcode adaptors can be ligated to fragments sequentially or simultaneously. As will be described in more detail herein, the ends of the common and barcode adaptors may be modified such that each adaptor segment will be ligated to the correct molecule in the correct orientation. Such modifications prevent 'aggregation' of adaptor segments or fragments by ensuring that the fragments cannot be ligated to each other, and that the adaptor segments can only be ligated in the illustrated orientation. In other embodiments, the adaptors used to tag the fragments in each well utilize a three-segment design. This embodiment is similar to the barcode adaptor design described above, except that the barcode adaptor segment is divided into two segments. This design allows for a large array of possible barcodes by allowing the combinatorial barcode adapter segments to be generated by joining different barcode segments together to form a complete barcode segment. This combinatorial design provides a larger corpus of possible barcode adaptors with a reduced number of full-size barcode adaptors that need to be generated. In other embodiments, the unique identification of each aliquot is achieved with 8-12 base pair error-corrected barcodes. In some embodiments, the same number of adaptors as wells are used (384 and 1536 in the non-limiting example above). In other embodiments, the costs associated with generating adaptors are reduced by a new combinatorial tagging approach based on two sets of 40 half-barcode adaptors. In one embodiment, library construction involves the use of two different adaptors. The a and B adaptors are easily modified to each contain different half-barcode sequences to produce thousands of combinations. In other embodiments, barcode sequences are incorporated on the same adapter. This can be achieved by dividing the B adaptors into two parts each having a half barcode sequence separated by a common overhang sequence for ligation. The two tag components each have 4-6 bases. The 8 base (2x 4 base) tag set is capable of uniquely tagging 65,000 aliquots. One additional base (2x 5 bases) would allow for error detection and a 12 base tag (2x 6 bases, 1200 ten thousand unique barcode sequence) could be designed to allow for substantial error detection and correction using Reed-Solomon design in 10,000 or more aliquots (U.S. patent application 12/697,995, published as US 2010/0199155, which is incorporated herein by reference). Both 2x 5 base and 2x 6 base tags may involve the use of degenerate bases (i.e., 'wild-type') to achieve optimal decoding efficiency. After tagging the fragments in each well, all fragments are combined or pooled to form a single population. These fragments can then be used to generate nucleic acid templates or library constructs for sequencing. Nucleic acid templates generated from these tagged fragments would be identifiable as belonging to a particular well based on the barcode tag adaptor attached to each fragment. Long Fragment Read (LFR) techniques SUMMARY The individual human genome is diploid in nature, with half of the homologous chromosomes being derived from each parent. The background of variations occurring on each individual chromosome can have profound effects on the expression and regulation of genes and other transcribed regions of the genome. Furthermore, it is of great clinical importance to determine whether two potentially harmful mutations occur within one or both alleles of a gene. The present methods for whole genome sequencing lack the ability to assemble parental chromosomes separately in a cost-effective manner and describe the background (haplotypes) in which the variations co-occur. Modeling experiments have shown that haplotype determination at the chromosome level requires information on allelic linkage in the range of at least 70-100 kb. This cannot be achieved with prior art techniques using amplified DNA, which are limited to reads of less than 1000 bases due to difficulties in consistent amplification of long DNA molecules and loss of linkage information in sequencing. The pairing technique can provide the equivalent of extended read lengths, but is limited to less than 10kb due to the inefficiency of generating such DNA libraries (due to the difficulty of circular DNA longer than a few kb in length). This approach also requires extreme read coverage to contact all heterozygotes. Single molecule sequencing of DNA fragments larger than 100kb, if feasible, can be used for haplotype determination when the accuracy of single molecule sequencing is high and the cost of detection/instrumentation is low. This is very difficult to achieve with high yields for short molecules, let alone for 100kb fragments. Recent human genome sequencing has been performed on short read length (<200bp), highly parallelized systems, starting with hundreds of nanograms of DNA. These techniques are excellent in producing large amounts of data quickly and economically. Unfortunately, short reads that are often paired with small pairing gap sizes (500bp-10kb) eliminate most of the SNP phase information beyond a few kilobases (McKernan et al, Genome Res.19:1527,2009). Furthermore, it is very difficult to maintain long DNA fragments in multiple processing steps without fragmentation due to shearing. Currently, three personal genomes, namely three of J.Craig Venter (Levy et al, PLoS biol.5: e254,2007) (One of India ancient Gitty-Raylen (HapMap Sample NA 20847; Kitzman et al, Nat. Biotechnol.29:59,2011) and two of European (Max Planck One [ MP1 ]; Suk et al, Genome Res.2011; Genome. cshlp.org/content/early/2011/09/02/gr.125047.111.full. pdf; and HapMap Sample NA 12878; Duitama et al, Nucl. acids Res.40: 2041. 2053,2012)) have been sequenced and diploid assembled. All involved cloning of long DNA fragments into constructs in a similar manner to Bacterial Artificial Chromosome (BAC) sequencing used during construction of human reference genomes (Venter et al, Science 291:1304,2001; Lander et al, Nature 409:860,2001). Although these methods generate longer phased contigs (350kb [ Levy et al, PLoS biol.5: e254,2007], 386kb [ Kitzman et al, nat. Biotechnol.29:59-63,2011] and 1Mb [ Suk et al, Genome Res.21: 1672-. In addition, whole chromosome haplotypes have been demonstrated by direct isolation of metaphase chromosomes (Zhang et al, nat. Genet.38: 382. 387, 2006; Ma et al, nat. methods 7: 299. 301, 2010; Fan et al, nat. Biotechnol.29:51-57,2011; Yang et al, Proc. Natl. Acad. Sci. USA 108:12-17,2011). These methods are excellent for remote haplotype determination, but have not been used for whole genome sequencing and require preparation and isolation of whole metaphase chromosomes, which can be challenging for some clinical samples. The LFR method overcomes these limitations. LFR involves DNA preparation and tagging together with associated algorithms and software to achieve precise assembly of separate sequences of parental chromosomes in a diploid genome (i.e., complete haplotype determination) at significantly reduced experimental and computational costs. LFR is based on the physical separation of long fragments of genomic DNA (or other nucleic acids) between multiple different aliquots, so that there is a low probability that there is any given region of the genome of both the maternal and paternal components present in the same aliquot. By placing a unique identifier in each aliquot and analyzing the multiple aliquots in total, the DNA sequence data can be assembled into a diploid genome, e.g., the sequence of each parent chromosome can be determined. LFRs do not require the cloning of fragments of complex nucleic acids into vectors, as in haplotype determination methods using large fragment (e.g., BAC) libraries. LFR also does not require direct isolation of individual chromosomes of an organism. Finally, LFR can be performed on individual organisms and no population of organisms is required to achieve haplotype phasing. As used herein, the term 'vector' means a plasmid or viral vector into which a foreign DNA fragment is inserted. The vector is used to introduce foreign DNA into a suitable host cell, where the vector and the inserted foreign DNA replicate due to the presence of, for example, a functional origin of replication or an autonomously replicating sequence in the vector. As used herein, the term 'cloning' refers to the insertion of a DNA fragment into a vector and the replication of the vector with the inserted foreign DNA in a suitable host cell. LFR can be used with the sequencing methods discussed in detail herein, and more generally as a pre-processing method with any sequencing technique known in the art, including both short read and longer read methods. LFR can also be used in conjunction with various types of assays including, for example, analyzing transcriptomes, methylation sets, and the like. Since it requires very little input DNA, LFR can be used to sequence one or a small number of cells and determine haplotypes, which can be particularly important for cancer, prenatal diagnostics, and personalized medicine. This may facilitate identification of familial genetic diseases, among others. By making it possible to distinguish the responses from two sets of chromosomes in a diploid sample, LFR also allows for higher confidence responses at variant and non-variant locations with low coverage. Other applications of LFR include resolving extensive rearrangements in the cancer genome and full-length sequencing of alternatively spliced transcripts. LFRs can be used to process and analyze complex nucleic acids, including but not limited to genomic DNA, which is purified or unpurified, including cells and tissues that are mildly damaged to release such complex nucleic acids without shearing and fragmenting such complex nucleic acids to multiple degrees. In one aspect, the LFR generates dummy read results of approximately 100-1000kb in length. In addition, LFR can also significantly reduce the computational requirements and associated costs of any short read result techniques. Importantly, LFR eliminates the need to extend the length of the sequencing results (if it reduces overall yield) of the reads. Additional benefits of LFR are substantial (10 to 1000 fold) reduction in error or questionable base response that can result from current sequencing technologies, typically 1 per 100kb, or 30,000 false positive responses per human chromosomal genome, and a similar number of undetected variants per human genome. This significant reduction in error minimizes the need to follow the construction of detection variants and facilitates diagnostic applications using human genome sequencing. In addition to being applicable to all sequencing platforms, LFR-based sequencing may be applicable to any application, including but not limited to the study of structural rearrangements in cancer genomes, analysis of fully methylated sets, haplotypes including methylation sites, and even reassembly applications to sequence complex polyploid genomes, such as metagenomics of genomes present in plants or new genomes. In contrast to the consensus sequences of the parent or related chromosomes only, LFR provides the ability to obtain the true sequence of each chromosome (despite its high similarity and the presence of long repeats and segment duplications). To generate such data, sequence continuity is generally established over a long DNA range, such as 100kb to 1 Mb. Yet another aspect of the invention includes software and algorithms for efficient use of LFR data for whole chromosome haplotype and structural variation localization and false positive/negative error correction to less than 300 errors per person's chromosome. In yet another aspect, the LFR technique of the invention reduces DNA complexity in each aliquot by 100-fold and 1000-fold depending on the aliquot and number of cells used. Complexity reduction and haplotype separation in long DNA larger than 100kb can facilitate more efficient and cost-effective (cost reduction up to 100-fold) assembly and detection of all variations in human and other diploid genomes. The LFR methods described herein may be used as a pre-processing step for sequencing a diploid genome using any sequencing method known in the art. In other embodiments, the LFR methods described herein may be used on a number of sequencing platforms including, for example, but not limited to, polymerase-based sequencing-by-synthesis (e.g., HiSeq 2500 system, Illumina, San Diego, CA), ligation-based sequencing (e.g., SOLiD 5500, Life Technologies Corporation, Carlsbad, CA), ion semiconductor sequencing (e.g., ion PGM or ion proton sequencer, Life Technologies Corporation, Carlsbad, CA), zero mode waveguide (e.g., PacBio RS sequencer, pacfic Biosciences, Menlo Park, CA), Nanopore sequencing (e.g., Oxford Nanopore Technologies ltd., Oxford, United Kingdom), pyrosequencing (e.g., Life Sciences 454, bract), or other sequencing Technologies. Some of these sequencing Technologies are short read-out Technologies, but others yield longer reads, such as GS FLX + (454Life Sciences; up to 1000bp), PacBio RS (Pacific Biosciences; about 1000bp), and Nanopore sequencing (Oxford Nanopore Technologies Ltd.; 100 kb). For haplotype phasing, longer reads are advantageous, require much fewer calculations, although they tend to have higher error rates, and errors in such long reads may need to be identified and corrected for according to the methods set forth herein before haplotype phasing. According to one embodiment of the present invention, the basic steps of LFR include: (1) dividing a long fragment of complex nucleic acid (e.g., genomic DNA) into aliquots, each aliquot containing one genomic equivalent of DNA; (2) amplifying the genomic fragments in each aliquot; (3) fragmenting the amplified genomic fragments to create short fragments (e.g., about 500 bases in length in one embodiment) of a size suitable for library construction; (4) tagging the short fragments to allow identification of the aliquot from which the short fragments originate; (5) merging the tagged fragments; (6) sequencing the pooled tagged fragments; and (7) analyzing the resulting sequence data to locate and assemble the data and obtain haplotype information. According to one embodiment, LFR produces theoretical 19-38x physical coverage of both maternal and paternal alleles of each segment using 384-well plates with 10-20% haploid genomes in each well. Initial DNA redundancy 19-38x ensured complete genome coverage and higher variant response and phasing accuracy. LFR avoids the need for subcloning of vectors or for isolating individual chromosomes (e.g., metaphase chromosomes) from complex nucleic acid fragments, and it can be fully automated, making it suitable for high-throughput, cost-effective applications. We have also developed techniques using LFR for error reduction and other purposes detailed herein. LFR methods have been disclosed in U.S. patent application nos. 12/816,365,12/329,365,12/266,385, and 12/265,593, and U.S. patent nos. 7,906,285,7,901,891, and 7,709,197, all of which are hereby incorporated by reference in their entirety. As used herein, the term 'haplotype' means a combination of alleles transmitted together at adjacent locations (loci) on a chromosome, or alternatively, a statistically correlated set of sequence variants on a single chromosome of a chromosome pair. Each individual has two sets of chromosomes, one male parent and the other female parent. Typically, DNA sequencing yields only genotypic information, i.e., the sequence of disordered alleles along a DNA segment. The alleles in each disordered pair are separated into two distinct sequences, each called a haplotype, for genotype inference haplotypes. Haplotype information is essential for many different types of genetic analysis, including disease association studies and inference of population ancestry. As used herein, the term 'phasing' (or resolution) means the classification of sequence data into two sets of parent chromosomes or haplotypes. Haplotype phasing refers to the problem of taking as input a set of genotypes for one individual or a population (i.e., more than one individual) and outputting a pair of haplotypes for each individual (one paternally and the other maternally). Phasing may involve resolving sequence data for a region of the genome, or as few as just two sequence variants in a read or contig, which may be referred to as local phasing or microphase. It may also involve phasing of larger contigs (typically including more than about 10 sequence variants) or even whole genome sequences, which may be referred to as 'universal phasing'. Optionally, the sequence variants are phased during genome assembly. Aliquot sampling of multiple genomic equivalents of complex nucleic acids The LFR method is based on the random physical division of the genome in a long fragment into multiple aliquots such that each aliquot contains one haploid genome. As the score of the genome in each set decreases, the statistical probability of having corresponding fragments from two parent chromosomes in the same set decreases significantly. In some embodiments, 10% of the genome equivalents are sampled equally into each well of a multi-well plate. In other embodiments, 1% to 50% of the genome equivalent of the complex nucleic acid is aliquoted into each well. As noted above, the number of aliquots and genome equivalents may depend on the number of aliquots, initial fragment size, or other factors. Optionally, denaturing the double-stranded nucleic acid (e.g., human genome) prior to aliquoting; in this manner, single-stranded complements can be distributed into different aliquots. According to one embodiment, each aliquot comprises 2, 4, 6, or more copies (or complements) of the majority of strands of the complex nucleic acid (or 2, 4, 6, or more complements if the double-stranded nucleic acid is denatured prior to aliquot sampling). For example, at 0.1 genome equivalents per aliquot (about 0.66 picograms or pg DNA at about 6.6pg per human genome), there is a 10% probability that two fragments will overlap, and there is a 50% probability that those fragments will originate from different parental chromosomes; this yields an overall probability that 95% of the base pairs in an aliquot are non-overlapping, i.e., a particular aliquot will provide no information for a given fragment, of 5%, because the aliquot contains fragments derived from both the maternal and paternal chromosomes. Uninformative aliquots can be identified because sequence data derived from such aliquots contain an increased amount of 'noise,' that is, impurities in the heterozygosity versus linkage matrix. Fuzzy Interference Systems (FIS) allow robustness against a certain degree of contamination, i.e. it allows correct connection despite contamination (up to a certain degree). Even smaller amounts of genomic DNA can be used, particularly in the context of microdroplets or nanodroplets or emulsions, where each droplet can contain one DNA fragment (e.g., a single 50kb fragment or about 1.5x 10-5 genomic equivalents of genomic DNA). Even at 50% of genome equivalents, most aliquots will be informative. At higher levels, e.g., 70% genome equivalents, informative wells can be identified and used. According to one aspect of the invention, 0.000015,0.0001,0.001,0.01,0.1,1,5,10,15,20,25,40,50,60, or 70% genomic equivalents of the complex nucleic acid is present in each aliquot. It will be appreciated that the dilution factor may depend on the initial size of the fragment. That is, using a mild technique to isolate genomic DNA, a fragment of about 100kb can be obtained, and then, the fragment is sampled in aliquots. Techniques that allow for larger fragments result in fewer aliquots being required, and techniques that generate shorter fragments may require more dilution. We have successfully performed all 6 enzymatic steps in the same reaction without DNA purification, which facilitates miniaturization and automation, and makes it feasible to adapt LFRs for use in a wide variety of platforms and sample preparation methods. According to one embodiment, each aliquot is contained in a separate well of a multiwell plate (e.g., a 384-well plate). However, any suitable type of container or system known in the art may be used to contain the aliquot, or the LFR method may be performed using a droplet or emulsion, as described herein. According to one embodiment of the invention, the volume is reduced to sub-microliter levels. In one embodiment, automated pipetting methods may be used in a 1536 well format. Generally, as the number of aliquots increases, e.g., to 1536, and the percentage of the genome drops to about 1% haploid genome, the statistical support for haplotypes increases significantly because the sporadic presence of both maternal and paternal haplotypes in the same well decreases. Thus, a large number of small aliquots, each with negligible mixed haplotype frequency, allows for the use of fewer cells. Similarly, longer fragments (e.g., 300kb or longer) help bridge segments lacking heterozygous loci. Nanoliter (nl) dispensing tools that provide 50-100nl of non-contact pipette (e.g., Hamilton Robotics Nano pipette tips, TTP LabTech Mosquito, etc.) can be used for fast and low cost pipetting to generate tens of genomic libraries in parallel. The increased number of aliquots (compared to 384-well plates) resulted in a greater reduction in genome complexity per well, which reduced overall computational cost by more than 10-fold and improved data quality. In addition, automation of this method increases throughput and reduces the hands-on cost of producing libraries. LFR using smaller aliquot volumes (including microdroplets and emulsions) Even further cost reduction and other advantages can be achieved using droplets. In some embodiments, LFR is performed with combinatorial tagging in an emulsion or microfluidic device. The volume drop to picoliter levels in 10,000 aliquots can achieve even greater cost reductions due to lower reagent and computational costs. In one embodiment, LFR uses a volume of 10 microliters (μ l) of reagent per well in a 384-well format. For example, such volumes can be reduced by using a commercial automated pipetting method in a 1536 well format. Further volume reduction can be achieved using nanoliter (nl) dispensing tools (e.g., Hamilton Robotics Nano pipetting heads, TTP LabTech Mosquito, etc.) that provide 50-100nl of non-contact pipettes that can be used for fast and low cost pipetting to generate tens of genomic libraries in parallel. Increasing the number of aliquots results in a greater reduction in genome complexity per well, which reduces overall computational cost and improves data quality. In addition, automation of this method increases throughput and reduces the cost of producing libraries. In other embodiments, the unique identification of each aliquot is achieved with 8-12 base pair error-corrected barcodes. In some embodiments, the same number of adaptors as wells are used. In other embodiments, a novel combinatorial tagging approach is used that is based on two sets of 40 half-barcode adaptors. In one embodiment, library construction involves the use of two different adaptors. The a and B adaptors are easily modified to each contain different half-barcode sequences to produce thousands of combinations. In other embodiments, barcode sequences are incorporated on the same adapter. This can be achieved by dividing the B adaptors into two parts each having a half barcode sequence separated by a common overhang sequence for ligation. The two tag components each have 4-6 bases. The 8 base (2x 4 base) tag set is capable of uniquely tagging 65,000 aliquots. One additional base (2x 5 bases) would allow for error detection and a 12 base tag (2x 6 bases, 1200 ten thousand unique barcode sequence) could be designed to allow for substantial error detection and correction using Reed-Solomon design in 10,000 or more aliquots. In an exemplary embodiment, both 2x 5 base and 2x 6 base tags are employed, including the use of degenerate bases (i.e., 'wild-cards') to achieve optimal decoding efficiency. A reduction in volume to picoliter levels (e.g., in 10,000 aliquots) can achieve even greater reagent and computational cost reductions. In some embodiments, this level of cost reduction and extensive aliquot sampling is achieved via combining LFR methods with combinatorial tagging to emulsion or microfluidic devices. The ability to perform all enzymatic steps in the same reaction without DNA purification facilitates the ability to miniaturize and automate this method and also results in adaptability to its wide variety of platforms and sample preparation methods. In one embodiment, the LFR method is used in conjunction with an emulsion-type device. The first step in adapting LFR to an emulsion type device is to prepare each drop of an emulsion reagent with a barcode-tagged combinatorial adaptor with a single unique barcode. Two sets of 100 half-barcodes were sufficient to uniquely identify 10,000 aliquots. However, increasing the number of half barcode adaptors to over 300 may allow random addition of barcode droplets to be combined with sample DNA with a low probability that any two aliquots contain the same barcode combination. Combinatorial barcode adaptor droplets can be generated and stored in reagents in a single tube for thousands of LFR libraries. In one embodiment, the present invention is expanded from 10,000 to 100,000 or more aliquot pools. In other embodiments, the LFR method is adapted to perform such expansion by increasing the number of initial half-barcode adaptors. These combinatorial adaptor droplets are then fused one-to-one with droplets containing ready-to-ligate DNA representing less than 1% of the haploid genome. Conservative estimates of 1nl and 10,000 droplets per droplet were used, representing a total volume of 10 μ l for the entire LFR library. Recent studies have also suggested improvements in GC preference and reductions in background amplification after amplification (e.g., by MDA) by reducing reaction volumes to nanoliter sizes. There are currently several classes of microfluidic devices (such as those sold by Advanced Liquid Logic, Morrisville, NC) or pico/nano-droplets (such as RainDance Technologies, Lexington, MA) that have pico/nano-droplet generation, fusion (3000/sec) and collection functions and can be used in such embodiments of LFR. In other embodiments, about 10-20 nanoliters are placed in plates or on glass slides in a format above 3072-6144 (still a cost-effective total MDA volume of 60 μ Ι without loss of computational cost savings or the ability to sequence genomic DNA from a small number of cells) using improved nanopipette or acoustic droplet ejection techniques (e.g., LabCyte inc., Sunnyvale, CA) or using microfluidic devices capable of processing up to 9216 individual reaction wells (e.g., devices produced by Fluidigm, South San Francisco, CA). Increasing the number of aliquots results in a greater reduction in genome complexity per well, which reduces overall computational cost and improves data quality. In addition, automation of this method increases throughput and reduces the cost of producing libraries. Amplification of According to one embodiment, the LFR method begins with a short treatment of genomic DNA with a 5 'exonuclease to create a 3' single stranded overhang that serves as the MDA initiation site. The use of exonucleases eliminates the need for a thermal or alkaline denaturation step prior to amplification and does not introduce preference into the population of fragments. Alkaline denaturation can be combined with 5' exonuclease treatment, which results in a further reduction of preference. The DNA was then diluted to subgenomic concentration and sampled in aliquots. After aliquot sampling, fragments in each well are amplified, for example, using the MDA method. In certain embodiments, the MDA reaction is a modified phi29 polymerase-based amplification reaction, although another known amplification method may be used. In some embodiments, the MDA reaction is designed to introduce uracil into the amplification product. In some embodiments, a standard MDA reaction using random hexamers is used to amplify the fragments in each well. In many embodiments, random 8-mer primers are used to reduce amplification bias in a population of fragments, as opposed to random hexamers. In other embodiments, several different enzymes may also be added to the MDA reaction to reduce amplification preferences. For example, low concentrations of non-processive 5' exonucleases and/or single-stranded binding proteins can be used to create 8-mer binding sites. Chemical agents such as betaine, DMSO, and trehalose may also be used to reduce preferences via a similar mechanism. Fragmentation According to one embodiment, after amplification of the DNA in each well, the amplification products are subjected to one round of fragmentation. In some embodiments, the fragment in each well is further fragmented after amplification using the CoRE method described above. To use the CoRE method, the MDA reaction used to amplify the fragments in each well is designed to incorporate uracil into the MDA product. Fragmentation of the MDA product can also be achieved via sonication or enzymatic treatment. If the CoRE method is used to fragment the MDA product, each well containing amplified DNA is treated with a mixture of Uracil DNA Glycosylase (UDG), DNA glycosylase-lyase endonuclease VIII, and T4 polynucleotide kinases to excise the uracil base and create a single base gap with a functional 5 'phosphate and 3' hydroxyl group. Nick translation via the use of a polymerase such as Taq polymerase results in double-stranded blunt end breaks, which generate ligatable fragments in a size range that depends on the concentration of dUTP added in the MDA reaction. In some embodiments, the CoRE method used involves removal of uracil by phi29 polymerization and strand displacement. After fragmentation of the MDA product, the ends of the resulting fragments can be repaired. Such repair may be necessary because many fragmentation techniques may generate termini with overhangs and termini with functional groups that are not available for subsequent ligation reactions, such as 3 'and 5' hydroxyl groups and/or 3 'and 5' phosphate groups. In many aspects of the invention, it may be useful to have fragments repaired to have blunt ends, and in some cases it may be desirable to alter the terminal photochemistry so that the correct phosphate and hydroxyl group orientations are not present, thereby preventing 'polymerization' of the target sequence. Control over the end chemistry can be provided using methods known in the art. For example, in some cases, the use of a phosphatase enzyme eliminates all phosphate groups such that all termini contain hydroxyl groups. One end of the 'activated' fragment can then be treated with alkaline phosphatase. Each end can then be selectively altered to allow for the linkage between the desired components. One end of the fragment may then be 'activated', in some embodiments by treatment with alkaline phosphatase. Following fragmentation and optionally end repair, the fragments are tagged with adaptors. Tagging Generally, the tag adapter arm is designed in two sections: one segment is common to all wells and the blunt ends directly link the fragments using methods described further herein. The second segment is unique to each well and contains a 'barcode' sequence, such that when the contents of each well are combined, fragments from each well can be identified. According to one embodiment, a 'common' adaptor is added as two adaptor arms: one arm is a blunt end attached to the 5 'end of the fragment, and the other arm is a blunt end attached to the 3' end of the fragment. The second segment of the tagged adapter is a 'barcode' segment that is unique to each well. This barcode is typically a unique nucleotide sequence and each fragment in a particular well is given the same barcode. As such, when tagged fragments from all wells are recombined for sequencing applications, fragments from the same well can be identified via identification of barcode adaptors. The barcode was ligated to the 5' end of the common adapter arm. Common adaptors and barcode adaptors can be ligated to fragments sequentially or simultaneously. The ends of the common and barcode adaptors may be modified so that each adaptor segment will be ligated to the correct molecule in the correct orientation. Such modifications prevent 'aggregation' of adaptor segments or fragments by ensuring that the fragments cannot be ligated to each other, and that the adaptor segments can only be ligated in the illustrated orientation. In other embodiments, the adaptors used to tag the fragments in each well utilize a three-segment design. This embodiment is similar to the barcode adaptor design described above, except that the barcode adaptor segment is divided into two segments. This design allows for a large array of possible barcodes by allowing the combinatorial barcode adapter segments to be generated by joining different barcode segments together to form a complete barcode segment. This combinatorial design provides a larger corpus of possible barcode adaptors with a reduced number of full-size barcode adaptors that need to be generated. According to one embodiment, after tagging the fragments in each well, all fragments are combined to form a single population. These fragments can then be used to generate the nucleic acid templates of the invention for sequencing. Nucleic acid templates generated from these tagged fragments can be identified as originating from a particular well according to the barcode tag adaptor attached to each fragment. Similarly, upon sequencing the tag, the genomic sequence to which it is attached can also be identified as originating from the well. In some embodiments, the LFR methods described herein do not include multiple levels or levels of fragmentation/aliquot sampling, as described in U.S. patent application No.11/451,692 filed on 6/13/2006, which is incorporated herein by reference in its entirety for all purposes. That is, some embodiments utilize only one round of aliquot sampling, and also allow for the reconstitution of aliquots for a single array, rather than using a different array for each aliquot. LFR using one or a small number of cells as a source of complex nucleic acid According to one embodiment, the LFR method is used to analyze the genome of a single cell or a small number of cells. The method for isolating DNA in this case is similar to the method described above, but can occur in a smaller volume. As discussed above, the isolation of long fragments of genomic nucleic acid from cells can be achieved by a variety of different methods. In one embodiment, the cells are lysed and the intact nuclei are pelleted with a gentle centrifugation step. Genomic DNA is then released via proteinase K and rnase digestion for several hours. In some embodiments, the material may be treated to reduce the concentration of residual cellular waste, such treatments being well known in the art and may include, but are not limited to, dialysis for a period of time (i.e., 2-16 hours) and/or dilution. Since such methods of isolating nucleic acids do not involve many destructive methods (such as ethanol precipitation, centrifugation, and vortexing), genomic nucleic acids remain largely intact, producing most fragments with a length of over 150 kilobases. In some embodiments, the fragments are about 100 to about 750 kilobases in length. In other embodiments, fragments are from about 150 to about 600, from about 200 to about 500, from about 250 to about 400, and from about 300 to about 350 kilobases in length. Once the DNA is isolated and before it is aliquoted into individual wells, the genomic DNA must be carefully fragmented to avoid loss of material, particularly loss of sequence from the end of each fragment, as loss of such material can lead to gaps in final genomic assembly. In one case, sequence loss is avoided by using rare nicking enzymes that create the start sites for polymerases such as phi29 polymerase at a distance of about 100kb from each other. As the polymerase creates a new DNA strand, it displaces the old strand, the end result being an overlapping sequence near the polymerase start site, resulting in very few sequence deletions. In some embodiments, the controlled use of 5' exonucleases (either before or during the MDA reaction) can facilitate multiple replications of the original DNA from a single cell, thus minimizing the growth of early errors via copy replication. In one aspect, the methods of the invention generate mass genome data from a single cell. Assuming no DNA loss, there is a benefit starting with a small number of cells (10 or less) instead of using an equivalent amount of DNA from a large preparation. Starting with less than 10 cells and accurately aliquoting substantially all DNA ensures consistent coverage in long fragments of any given region of the genome. Starting with less than 5 cells allows 4-fold or greater coverage per 100kb DNA fragment in each aliquot without increasing the total number of reads above 120Gb (20-fold coverage of a 6Gb diploid genome). However, large aliquots (10,000 or more) and longer DNA fragments (>200kb) are even more important for sequencing from a few cells, because for any given sequence there is only as many starting cell numbers as there are overlapping fragments, and the appearance of overlapping fragments from two parent chromosomes in one aliquot can be a devastating loss of information. LFR is well suited to this problem because it produces excellent results starting with only about 10 cells equivalent to the starting input genomic DNA, and even one single cell will provide enough DNA to perform LFR. Generally, the first step in LFR is low preference whole genome amplification, which can be used in particular for single cell genome analysis. Even single molecule sequencing methods may require some level of DNA amplification from single cells due to DNA strand breaks and DNA loss in the process. The difficulty in sequencing single cells comes from attempting to amplify the entire genome. Studies performed on bacteria using MDA have suffered from a loss of roughly half of the genome in the final assembled sequence and a considerable amount of variation in the coverage of those sequencing intervals. This can be explained in part by the initial genomic DNA with nicks and strand breaks, which cannot be replicated at the ends and thus are lost during the MDA process. LFR provides a solution to this problem by creating long overlapping fragments of the genome prior to MDA. In order to achieve this, according to one embodiment of the invention, a mild method is used to isolate genomic DNA from the cells. The largely intact genomic DNA was then lightly treated with common nicking enzymes to generate a semi-randomly nicked genome. Then, the strand displacement capability of phi29 was used to aggregate from the nicks, creating very long (>200kb) overlapping fragments. These fragments then serve as starting templates for LFR. Methylation analysis using LFR In yet another aspect, the methods and compositions of the invention are used in genomic methylation analysis. Several methods are currently available for global genomic methylation analysis. One method involves bisulfate treatment of genomic DNA and sequencing of repetitive elements or parts of the genome obtained by fragmentation with methylation specific restriction enzymes. This technique yields information about global methylation, but does not provide locus-specific data. The next higher resolution level uses DNA arrays and is limited by the number of features on the chip. Finally, the highest resolution and most expensive method requires bisulfate treatment followed by sequencing of the entire genome. Using LFR, it is possible to sequence all the bases of a genome and assemble a complete diploid genome with numerical information about the methylation level of each cytosine position in the human genome (i.e., 5-base sequencing). In addition, LFR allows for the joining of methylated sequence blocks of 100kb or greater to sequence haplotypes, providing methylated haplotypes determination, i.e., information that cannot be achieved with any currently available method. In one non-limiting exemplary embodiment, the methylation state is obtained in a method in which genomic DNA is first sampled in aliquots and denatured for MDA. Next, the DNA is treated with bisulfite (i.e., a step in which the DNA needs to be denatured). The remaining preparations followed those methods described in, for example, U.S. application serial nos. 11/451,692 and 12/335,168 filed by 6/13/2006 and 12/15/2008, each of which is hereby incorporated by reference in its entirety for all purposes and in particular for all teachings relating to nucleic acid analysis of fragment mixtures according to long fragment read results techniques. In one aspect, MDA will amplify each strand of a particular fragment, which independently produces 50% reads for any given cytosine position that are not affected by bisulfite (i.e., cytosine is not affected by the bisulfite relative to the base guanine) and 50% provides the methylation state. The reduced DNA complexity of each aliquot facilitates accurate localization and assembly of less informative, typically 3-base (a, T, G) reads. Bisulfite treatment has been reported to fragment DNA. However, denaturation and careful titration with bisulfate buffer can avoid extensive fragmentation of genomic DNA. A 50% conversion of cytosine to uracil can be tolerated in LFRs, which allows for a reduction in DNA exposure to bisulfite to minimize fragmentation. In some embodiments, some degree of fragmentation after aliquot sampling is acceptable because it does not affect the haplotype determination. Analysis of cancer genomes using LFR It has been proposed that more than 90% of cancers contain significant loss or gain in human genomic regions, called heteroploidy, and it has been observed that some individual cancers contain more than 4 copies of some chromosomes. This increased complexity of chromosomes and the copy number of regions within chromosomes makes sequencing cancer genomes substantially more difficult. The ability of LFR technology to sequence and assemble very long (>100kb) genomic fragments makes it well suited for sequencing of the entire cancer genome. Error reduction by sequencing target nucleic acids in multiple aliquots According to one embodiment, the target nucleic acid is divided into a plurality of aliquots, each containing an amount of the target nucleic acid, even without performing LFR-based phasing and using standard sequencing methods. In each aliquot, the target nucleic acid is fragmented (if fragmentation is required), and the fragments are tagged with an aliquot-specific tag (or set of aliquot-specific tags) prior to amplification. Alternatively, in processing a tissue sample, one or more cells may be dispensed into each of a plurality of aliquots, followed by cell disruption, fragmentation, tagging of the fragments with an aliquot-specific tag, and amplification. In either case, the amplified DNA from each aliquot can be sequenced separately or pooled and sequenced after pooling. One advantage of this method is that errors introduced by amplification (or other steps occurring in each aliquot) can be identified and corrected for. For example, a base response (e.g., identifying a particular base, such as a, C, G, or T) at a particular location (e.g., relative to a reference) of the sequence data may be accepted as true if the base response is present in the sequence data from two or more aliquots (or other threshold number), or in substantially the majority of expected aliquots (e.g., in at least 51, 70, or 80%), where the denominator may be limited to an aliquot having a base response at the particular location. The base response may include an allele that alters heterozygosity or potential heterozygosity. A base response at a particular position may be accepted as false if it is present in only one aliquot (or other threshold number of aliquots), or in a substantially few aliquots (e.g., less than 10, 5, or 3 aliquots or as measured by relative numbers, such as 20 or 10%). The threshold value may be predetermined or dynamically determined based on sequencing data. If the base response at a particular position is not present in substantially a few and in substantially most of the expected aliquots (e.g., in 40-60%), it may be converted/accepted as 'non-responsive'. In some embodiments and implementations, a number of parameters (e.g., in distributions, probabilities, and/or other functions or statistics) may be used to characterize what may be considered a substantially small number or a substantially large number of aliquots. Examples of such parameters include, but are not limited to, one or more of the following: identifying the number of base responses of a particular base; coverage or total number of responding bases at a particular position; generating a number and/or identity of unique aliquots of sequence data comprising specific base responses; generating a total number of unique aliquots of sequence data comprising at least one base response at a particular location; a reference base at a specific position; and so on. In one embodiment, a combination of the above parameters for a particular base response can be input to a function to determine a score (e.g., probability) for the particular base response. The score can then be compared to one or more threshold values as part of determining whether the base response is acceptable (e.g., above the threshold), erroneous (e.g., below the threshold), or non-responsive (e.g., if all scores of the base response are below the threshold). The determination of the base response may depend on the scores of other base responses. As a basic example, if a base response A is present in more than 35% (scoring examples) of aliquots containing reads for a location of interest, and a base response C is present in more than 35% of these aliquots, and the other base responses each have a score of less than 20%, then the location can be considered to be heterozygous for A and C, possibly subject to other criteria (e.g., a minimum number of aliquots containing reads at the location of interest). As such, each score may be input into another function (e.g., a heuristic, which may use comparison or fuzzy logic) to provide a final determination of the base response for the location. As another example, a specific number of aliquots containing base responses may be used as a threshold. For example, when analyzing cancer samples, there may be low prevalence somatic mutations. In such cases, the base response may occur in less than 10% of the aliquots covering the position, but the base response may still be considered correct, possibly subject to other criteria. As such, various embodiments may use absolute or relative numbers, or both (e.g., as inputs to comparison or fuzzy logic). Also, such numbers of aliquots may be input to a function (as mentioned above), as well as a threshold corresponding to each number, and the function may provide a score that may also be compared to one or more thresholds to make a final determination regarding the base response at a particular location. Further examples of error correction functions relate to sequence errors in the original reads that result in putative variant responses that are inconsistent with other variant responses and their haplotypes. If 20 reads of variant a were present in 9 and 8 aliquots belonging to the respective haplotype, and 7 reads of variant G were present in 6 wells (5 or 6 of which were shared with the aliquot with the a read), the logic may reject variant G as a sequencing error because for a diploid genome only one variant may reside at one position in each haplotype. Variant a gets substantially more reading support, while G reads essentially follow an aliquot of a reads, indicating that they are most likely due to an erroneous read G instead of a. If the G reads are almost exclusively in an aliquot separate from a, this may indicate that the G reads are mislocalized or that they are from contaminating DNA. Identification of extensions in regions with short tandem repeats (extensions) Short Tandem Repeats (STRs) in DNA are segments of DNA that have a strong periodic pattern. STR occurs when a pattern of two or more nucleotides repeats and the repeated sequences are directly adjacent to each other; the repeats may be complete or incomplete, i.e., may have several base pairs that do not match the periodic motif. Typically, the pattern ranges from 2 to 5 base pairs (bp) in length. STRs are typically located in non-coding regions, such as in introns. Short Tandem Repeat Polymorphisms (STRPs) occur when homologous STR loci differ in the number of repeats between individuals. STR analysis is often used to determine genetic profiles for forensic purposes. STRs present in exons of a gene may represent hypermutated regions associated with human disease (Madsen et al, BMC Genomics 9:410,2008). In the human genome (and genomes of other organisms), STRs include trinucleotide repeats, such as CTG or CAG repeats. Trinucleotide repeat expansion, also known as triplet repeat expansion, is caused by slippage during DNA replication and is associated with certain diseases classified as trinucleotide repeat disorders such as huntington's disease. Generally, the greater the expansion, the more likely it is to cause or increase the severity of the disease. This property leads to the 'early appearance' feature seen in trinucleotide repeat disorders, that is, the trend of decreasing age and increasing severity of symptoms through the onset of disease in successive generations of the affected family due to the expansion of these repeats. The identification of the expansion of trinucleotide repeats can be used to accurately predict onset age and disease progression for trinucleotide repeat disorders. The extension of STRs, such as trinucleotide repeats, can be difficult to identify using next generation sequencing methods. Such augmentation cannot be localized and may be absent or present in the library inadequately. Using LFR, it is possible to see a significant decrease in sequence coverage in STR regions. For example, a region with STRs will characteristically have a lower level of coverage than a region without such repeats, and if there is an expansion of the region, there will be a substantial reduction in coverage in the region, which is observable in a map of coverage versus location in the genome. FIG. 14 shows an example of the detection of repeated expansion of CTG in affected embryos. LFR is used to determine the parent haplotypes of an embryo. In the mean normalized clone coverage versus position plot, haplotypes with expanded CTG repeats have no or very little DNB across the expansion region, resulting in a reduction in coverage in the region. Reductions can also be detected in the combined sequence coverage of both haplotypes; however, a haplotype drop may be more difficult to identify. For example, if the sequence coverage is about 20 on average, the area with the extension will have a significant drop, for example to 10 if the affected haplotype has 0 coverage in the extension. Thus, a 50% reduction occurs. However, if the sequence coverage of the two haplotypes were compared, the coverage was 10 in the normal haplotype and 0 in the affected haplotype, which was a 10 drop, but the overall percentage was 100% drop. Alternatively, one can analyze relative amounts that are 2:1 for the combined sequence coverage (normal versus coverage in the extension), but 10:0 (haplotype 1 versus haplotype 2), which is infinite or 0 (depending on how the ratio is formed), thus a large difference. Diagnostic use of sequence data Sequence data generated using the methods of the invention can be used for a wide variety of purposes. According to one embodiment, the sequencing methods of the invention are used to identify sequence variations in complex nucleic acid sequences (e.g., whole genome sequences), for example, which provide information about the presence or prognosis of a patient or characteristic or medical state of an embryo or fetus, such as the sex of the embryo or fetus or a disease with a genetic component including, for example, cystic fibrosis, sickle cell anemia, marfan's syndrome, huntington's disease and hemochromatosis or a variety of cancers, such as breast cancer. According to another embodiment, the sequencing method of the invention is used to provide sequence information, which starts with 1-20 cells from a patient (including but not limited to a fetus or embryo) and estimates the characteristics of the patient based on the sequence. Cancer diagnostics Whole genome sequencing is a valuable tool in assessing the genetic basis of a disease. Many genetically based diseases (e.g., cystic fibrosis) are known. One application of whole genome sequencing is cancer understanding. The most important impact of next generation sequencing on cancer genomics is the ability to resequence, analyze, and compare matched tumor and normal genomes of a single patient and multiple patient samples of a given cancer type. Using whole genome sequencing, a whole range of sequence variations can be considered, including germline susceptibility loci, somatic Single Nucleotide Polymorphisms (SNPs), small insertion and deletion (indel) mutations, Copy Number Variation (CNVs), and Structural Variants (SVs). Typically, the cancer genome consists of the patient's germline DNA, on which somatic genomic alterations have been superimposed. Somatic mutations identified by sequencing can be classified as 'driver' or 'passenger' mutations. So-called driver mutations are those that directly contribute to tumor progression by conferring a growth or survival advantage to the cell. Passenger mutations encompass mesosomatic mutations that have been obtained during errors in cell division, DNA replication, and repair; these mutations can be obtained when the cell is phenotypically normal or after a neoplastic change is evident. Historically, attempts have been made to elucidate the molecular mechanisms of cancer, and several 'driver' mutations or biomarkers, such as HER2/neu2, have been identified. Based on such genes, therapeutic protocols have been developed to specifically target tumors with known genetic changes. An example of a best defined example of this approach is the targeting of HER2/neu in breast cancer cells by trastuzumab (Herceptin). However, cancer is not a simple single-cause disease, but is instead characterized by a combination of genetic changes that may vary from individual to individual. Thus, these other perturbations to the genome may render some drug regimens ineffective for certain individuals. Cancer cells for whole genome sequencing may be obtained from whole tumor biopsies (including micro-biopsies of small numbers of cells), cancer cells isolated from the patient's bloodstream or other bodily fluids, or any other source known in the art. Pre-implantation genetic diagnostics One application of the method of the invention is for pre-implantation genetic diagnostics. About 2 to 3% of the born infants have some types of major birth defects. The risk of some problems due to genetic segregation of genetic material (chromosomes) increases with maternal age. About 50% of the chances of these types of problems are due to down syndrome, which is the third copy of chromosome 21 (trisomy 21). The other half is derived from other types of chromosomal abnormalities, including trisomy, point mutations, structural variations, copy number changes, and the like. Many of these chromosomal problems result in badly affected infants or even infants that do not survive to delivery. In medicine and (clinical) genetics, pre-implantation genetic diagnostics (PGD or PIGD), also known as embryo screening, refers to procedures performed on embryos prior to implantation, sometimes even prior to fertilization. PGD may allow parents to avoid selective pregnancy termination. The term pre-implantation genetic screening (PGS) is used to refer to a procedure that does not look for a particular disease, but uses PGD technology to identify embryos that are at risk due to, for example, genetic conditions that can lead to disease. The procedure performed on sexual cells prior to fertilization may instead be referred to as a method of oocyte or sperm selection, although the method and purpose partially overlaps with PGD. Pre-implantation genetic profiling (PGP) is a method of assisted reproductive technology to perform selection of embryos that appear to have the greatest chance of successful pregnancy. PGP is mainly implemented as a screen for detecting chromosomal abnormalities such as aneuploidy, reciprocal and robertson translocations, and other abnormalities such as chromosomal inversion or deletion, in women of late maternal age and in patients who have failed in repeated In Vitro Fertilization (IVF). In addition, PGP can examine genetic markers for characteristics, including various disease states. PGP uses the latter principle that since many chromosomal inheritance explain most cases of pregnancy loss and a large proportion of human embryos are aneuploid, selective replacement of euploid embryos should improve the chances of successful IVF treatment. Whole genome sequencing provides an alternative to methods for comprehensive chromosome analysis, such as array-wide genome hybridization (aCGH), quantitative PCR, and SNP microarrays. For example, whole genome sequencing can provide information about single base changes, insertions, deletions, structural changes, and copy number changes. Since PGD can be performed on cells from different developmental stages, the biopsy procedure varies accordingly. Biopsies can be performed at all pre-implantation stages, including but not limited to unfertilized and fertilized oocytes (for polar bodies, PB), for three day cleavage stage embryos (for blastomeres) and for blastocysts (for trophectoderm cells). In view of the foregoing detailed description of the invention, according to one aspect of the invention, there is provided a method for sequencing complex nucleic acids of an organism (e.g., a mammal such as a human, whether a single organism or a population comprising more than one individual), such method comprising: (a) aliquoting a sample of the complex nucleic acid to generate a plurality of aliquots, each aliquot containing an amount of the complex nucleic acid; (b) sequencing the amount of complex nucleic acid from each aliquot to generate one or more reads from each aliquot; and (c) assembling the reads from each aliquot, thereby generating an assembled sequence of complex nucleic acids comprising no more than 1, 0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0.08,0.06,0.04 or less false single nucleotide variants per megabase at a response rate of 70,75,80,85,90, or 95% or greater. If the complex nucleic acid is a mammalian (e.g., human) genome, optionally, the assembled sequence has a genome response rate of 70% or greater and an exome response rate of 70,75,80,85,90 or 95% or greater. According to one embodiment, the complex nucleic acid comprises at least 1 gigabase. According to one embodiment of such a method, the complex nucleic acid is double-stranded, and the method comprises separating the single strands of the double-stranded complex nucleic acid prior to aliquot sampling. According to another embodiment, such methods comprise fragmenting the amount of complex nucleic acid in each aliquot to generate fragments of complex nucleic acid. According to one embodiment, such methods further comprise tagging the fragments of the complex nucleic acid in each aliquot with an aliquot-specific tag (or set of aliquot-specific tags), from which the aliquot from which the tagged fragments originate can be determined. In one embodiment, such tags are polynucleotides, including, for example, tags comprising an error correction code or error correction code, including but not limited to Reed-Solomon error correction codes. According to another embodiment, such methods comprise pooling aliquots prior to sequencing. According to another embodiment of such methods, the sequence comprises a base response at a sequence position, and such methods comprise identifying a base response as authentic if it originates from two or more aliquots, or from three or more reads originating from two or more aliquots. According to another embodiment, such methods comprise identifying a plurality of sequence variants in the assembled sequence and phasing the sequence variants. According to another embodiment of such methods, the sample of complex nucleic acids comprises 1 to 20 cells of an organism or genomic DNA isolated from a cell, which may be purified or unpurified. According to another embodiment, the sample comprises 1pg-100ng, such as 1pg,6pg,10pg,100pg,1ng,10ng or 100ng genomic DNA, or 1pg to 1ng, or 1pg to 100pg, or 6pg to 100 pg. For reference purposes, a single human cell contains about 6.6pg genomic DNA. According to another embodiment, such methods comprise amplifying the amount of complex nucleic acid in each aliquot. According to another embodiment of such a method, the complex nucleic acid is selected from the group consisting of: genomes, exomes, transcriptomes, methylation sets, mixtures of genomes of different organisms, mixtures of genomes of different cell types of organisms, and subgroups thereof. According to another embodiment of such methods, the assembly sequence has an 80x,70x,60x,50x,40x,30x,20x,10x, or 5x coverage. Lower coverage may be used with longer read results. In accordance with another aspect of the invention, an assembled sequence of mammalian complex nucleic acids is provided that comprises less than 1 false single nucleotide variant per megabase at a response rate of 70% or greater. In accordance with another aspect of the present invention, there is provided a method of sequencing a complex nucleic acid of an organism, the method comprising: (a) providing a sample comprising 1pg to 10ng of complex nucleic acid; (b) amplifying the complex nucleic acid to generate an amplified nucleic acid; and (c) sequencing the amplified nucleic acids to generate sequences having a complex nucleic acid response rate of at least 70%. According to one such method, the complex nucleic acid is unpurified. According to another embodiment, such methods comprise amplifying complex nucleic acids by multiple displacement amplification. According to another embodiment, such methods comprise amplifying the complex nucleic acid by at least 10,100,1000,10,000 or 100,000 fold or more. According to another embodiment of such methods, the sample comprises 1 to 20 cells (or nuclei) comprising complex nucleic acids. According to another embodiment, such methods comprise lysing cells (or nuclei) comprising the complex nucleic acid and cellular impurities, and amplifying the complex nucleic acid in the presence of the cellular impurities. According to another embodiment of such methods, the cells are circulating non-blood cells from the blood of a higher organism. According to another embodiment of such a method, the assembled sequence has a response rate of 70,75,80,85,90 or 95% or more. According to another embodiment of such methods, the sequence comprises 2,1,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0.08,0.06,0.04 or less pseudo single nucleotide variants per megabase. According to another embodiment, such methods further comprise: sampling a sample aliquot to generate a plurality of aliquots, each aliquot containing an amount of a complex nucleic acid; amplifying the amount of the complex nucleic acid in each aliquot to generate amplified nucleic acid in each aliquot; sequencing the amplified nucleic acids from each aliquot to generate one or more reads from each aliquot; and assembling the reads to generate a sequence. According to another embodiment, such methods further comprise: fragmenting the amplified nucleic acid in each aliquot to generate fragments of the amplified nucleic acid in each aliquot; and tagging fragments of the amplified nucleic acids in each aliquot with an aliquot-specific tag to generate tagged fragments in each aliquot. According to another embodiment of such methods, a base response at a sequence position is accepted as true if it is present in reads from two or more aliquots, or more strictly, occurs 3 or more times in reads from two or more aliquots. According to another embodiment, such methods further comprise identifying sequence variations in the sequence that provide information about a characteristic (e.g., medical state) of the organism. According to another embodiment, the cells are circulating non-blood cells from the blood (or other sample) of a higher organism, including but not limited to fetal cells from maternal blood and cancer cells from the blood of a patient with cancer. According to another embodiment of the invention, the complex nucleic acid is a Circulating Nucleic Acid (CNA). As such, the characteristics of the organism to be assessed may include, but are not limited to, the presence of cancer and information about the cancer (whether or not the organism is pregnant), and gender or genetic information about the fetus carried by the pregnant individual. For example, such methods can be used to identify single base variations, insertions, deletions, copy number changes, structural changes or rearrangements, and the like, associated with disease likelihood, medical diagnosis or prognosis, and the like. In accordance with another embodiment of the present invention, there is provided a method of assessing the genetic status (e.g., sex, paternity, presence or absence of genetic abnormalities or genotype associated with predisposition to disease, etc.) of an embryo comprising: (a) providing about 1-20 embryonic cells; (b) obtaining an assembly sequence generated by sequencing genomic DNA of the cell, wherein the assembly sequence has a response rate of at least 80%; and (c) comparing the assembled sequence to a reference sequence to assess the genetic status of the embryo. For example, such methods can be used to identify single base variations, insertions, deletions, copy number changes, structural changes or rearrangements, and the like, associated with disease likelihood, medical diagnosis or prognosis, and the like. In accordance with another embodiment, a method of assessing the genetic status (e.g., gender, paternity, presence or absence of genetic abnormalities or genotype associated with predisposition to disease, etc.) of an embryo is provided comprising: (a) providing about 1-20 embryonic cells; (b) obtaining an assembly sequence generated by sequencing genomic DNA of the cell, wherein the assembly sequence has a response rate of at least 80% of an embryonic genome; and (c) comparing the assembled sequence to a reference sequence to assess the genetic status of the embryo. According to another aspect of the present invention there is provided an assembled fully human genomic sequence comprising no more than 1 pseudo single nucleotide variant per megabase and a response rate of at least 70%, wherein said sequence is generated by sequencing 1pg-10ng of human genomic DNA. In accordance with another aspect of the invention, there is provided a method for phasing genomic sequence variants of an individual organism comprising a plurality of chromosomes, the method comprising: (a) providing a sample comprising a mixture of vector-free fragments of each of the plurality of chromosomes; (b) sequencing the vector-free fragments to generate a genomic sequence comprising a plurality of sequence variants; and (c) phasing the sequence variants. According to one embodiment, such methods comprise phasing at least 70,75,80,85,90, or 95% or more of the sequence variants. According to another embodiment of such methods, the genomic sequence has a response rate of at least 70% of the genome. According to another embodiment of such a method, the sample comprises 1pg to 10ng of the genome, or 1 to 20 cells of the individual organism. According to another embodiment of such methods, the genomic sequence has less than 1 pseudo single nucleotide variant per megabase. In accordance with another aspect of the invention, there is provided a method for phasing genomic sequence variants of an individual organism comprising a plurality of chromosomes, the method comprising: providing a sample comprising fragments of the plurality of chromosomes; sequencing the fragments without cloning the fragments in a vector to generate a whole genome sequence, wherein the whole genome sequence comprises a plurality of sequence variants; and phasing the sequence variants. According to one embodiment of such a method, phasing of sequence variants occurs during assembly of the whole genome sequence. Examples Example 1: comparison of DNA amplification methods Pre-implantation genetic diagnostics (PGD) is a form of prenatal diagnostics, consisting of genetically screening embryos produced by In Vitro Fertilization (IVF) (usually 10 on average per cycle) before they are transferred to the future mother. It is generally applicable to women of advanced maternal age (greater than 34 years) or couples at risk of transmitting genetic disease. The techniques currently used for genetic screening are Fluorescence In Situ Hybridization (FISH), Comparative Genomic Hybridization (CGH), SNP arrays and array CGH for detecting chromosomal abnormalities, and SNP arrays and PCR for detecting genetic defects. PGDs for single gene defects currently consist of custom designed assays unique to each patient, often combining specific mutation detection with linkage analysis as backups and to control and monitor contamination. Typically, 1 cell is obtained from each embryo biopsy on day 3 of development and the results are given on day 5 (which is the closest day an embryo can be transferred). Blastocyst biopsy was initially applied, consisting of a biopsy of 3-15 cells from the trophectoderm of blastocyst (day 5 embryo), followed by embryo freezing. Embryos can be kept frozen indefinitely without significant loss of potential, which is suitable for whole genome sequencing, allowing biopsies to be obtained at one site and then transferred to another site for whole genome sequencing. Whole genome sequencing of blastocyst biopsies would enable a 'universal' PGD test for single gene defects and other genetic abnormalities that can be identified by this technique. After conventional ovarian stimulation and aspiration, eggs were fertilized by intracytoplasmic sperm injection (ICSI) to avoid sperm contamination in PGD testing. After growth to day 3, embryos were taken using a fine glass needle biopsy and one cell was removed from each embryo. Each blastomere was added individually to a clean tube, covered with molecular grade oil, and shipped on ice to the PGD laboratory. Immediately after arrival, the samples were treated with a test designed to amplify the mutation of CTG repeat expansion in the gene DMPK and two linked markers. After clinical PGD testing and embryo transfer, unused embryos were donated to the IVF clinic and used in developing new PGD testing formats. 8 blastocysts were donated and used in these experiments. Blastocyst biopsies provide approximately 6.6 picograms (pg) of genomic DNA per cell. Amplification provides sufficient DNA for whole genome sequencing. FIG. 15 shows the results of amplification of 1.031pg, 8.25pg and 66pg purified genomic DNA standards and 1 or 10 PVP40 cells by MDA using our protocol (as described below). The MDA reaction can be run as long as necessary to obtain the amount of DNA required for a particular sequencing method (e.g., 30 minutes to 120 minutes). It is expected that the greater the degree of amplification, the more GC preferences will be generated. Two DNA amplification methods were compared to identify a method that generates template DNA of sufficient quality for whole genome sequence analysis with minimal introduction of GC bias. We compared our protocol to SurePlex amplification (Rubicon Genomics inc., Ann Arbor, Michigan) and modified MDA commonly used for array CGH. Biopsies of 10-20 cells were obtained from embryos affected by the R-1MT mutation of myotonic dystrophy. Samples were lysed and DNA denatured in a single tube, then amplified by MDA using our protocol and SurePlex kit according to the manufacturer's instructions. Approximately 2ug of DNA was generated by both amplification methods. Prior to whole genome sequence analysis, the amplified samples were screened with 96 independent qPCR markers spread across the genome to select the sample with the lowest amount of preference. The results are shown in FIG. 16. Briefly, we determined the average number of cycles across the entire plate and subtracted this number from each individual marker to calculate the 'Δ cycle' number. The Δ cycles were plotted against the GC content of 1000 base pairs surrounding each marker to indicate the relative GC bias of each sample. To ascertain the overall 'noise' of the sample, the absolute values of each Δ cycle are summed to produce a 'Δ sum' measure. The lower Δ sums and relatively flat data plots against GC content yielded well-represented whole genome sequences in our experience. Δ sums are 61 (for our MDA method) and 287 (for SurePlex amplified DNA), indicating that our protocol produces much less GC preference than SurePlex protocol. Example 2: complete genome sequencing of blastocyst biopsies for Pre-Implantation genetic diagnostics (PGD) Modified Multiple Displacement Amplification (MDA) (Dean et al (2002) Proc Natl Acad Sci U S A99, 5261-. Briefly, 5-20 cells from each 5-day-old blastocyst were isolated, frozen, and shipped on dry ice from the laboratory where they were isolated. The sample is thawed and lysed to release the genomic DNA. In the case of impure genomic DNA away from cellular impurities, the DNA was alkali denatured by addition of 1. mu.l 400mM KOH/10mM EDTA. Whole genome amplification of embryonic genomic DNA was performed using a phi29 polymerase-based Multiple Displacement Amplification (MDA) reaction to generate sufficient amounts of DNA (approximately 1. mu.g) for sequencing. 1 min after alkaline denaturation, thiol-protected random 8-mers were added to the denatured DNA. After 2 minutes the mixture was neutralized and a master mix containing the final concentrations of 50mM Tris-HCl (pH 7.5),10mM MgCl2,10mM (NH4)2SO4,4mM DTT, 250. mu.M dNTPs (USB, Cleveland, OH) and 12 units phi29 polymerase (Enzymatics, Beverly, MA) was added to produce a total reaction volume of 100 ul. MDA was reacted at 37 ℃ for 45 minutes and inactivated at 65 ℃ for 5 minutes. Approximately 2. mu.g of DNA was generated by MDA reaction. This amplified DNA was then fragmented and used for library construction and sequencing, as described above. Myotonic dystrophy type 1 (DM1) is an autosomal dominant disease caused by the expansion of trinucleotide repeats in the 3' untranslated region of the gene encoding myotonic dystrophy protein kinase (DMPK), i.e. cytosine-thymine-guanine (CTG) n. We examined clonal coverage of DMPK CTG repeats. The sequencing techniques described herein result in 35bp paired end reads, which typically span about 400 bp. For the uninvolved individual and an unknown sample, 400bp is sufficient to span this CTG repeat region of both alleles, resulting in a copy number of about 2. In the affected individuals and an unknown sample, a copy number of about 1 was observed, suggesting that the repeat expansion is too large for 400bp paired ends to span; only the unaffected alleles have coverage in this region. Table 1 below provides summary information for locating and assembling PGD embryo samples. All variation and localization statistics were relative to the National Center for Biotechnology Information (NCBI) version 37 human genome reference assembly. Samples 2A, 5B and 5C had poor amplification quality, resulting in less genomic response and a reduced total number of SNPs identified. Samples 5B and 5C were different biopsies from the same embryo. Sample NA20502 was processed according to standard protocols before library preparation and was not amplified. Fig. 17 shows the genome coverage of two samples (7C and 10C). Coverage was plotted using a 10 megabase moving average of a 100 kilobase coverage window normalized to haploid genome coverage. The dashed lines for copy numbers 1 and 3 represent haploid and triploid copy numbers, respectively. These two embryos are male and have haploid copy numbers for the X and Y chromosomes. No other loss or gain of whole chromosomes or large segments of chromosomes was evident in these samples. The worst performing sample achieved 85% genome coverage, while the best sample covered 95% of the genome, i.e., at a level similar to standard whole genome sequencing methods ('standard sequencing') performed by the methods described above using a few micrograms of purified, unamplified human genomic DNA. Generally, coverage is 'noisy' compared to standard sequencing, but using a moving average of 10 megabases allows for accurate detection of whole genome and chromosomal arm amplifications and deletions. We have also demonstrated that a number of polymorphisms can be detected and that the risk of developing certain diseases, in addition to DMPK mutations, can be used for blastocyst implantation selection. In this example, the starting genomic DNA was extensively amplified (more than about 10-fold necessary) to ensure that sufficient amounts of genomic DNA were available for sequencing. Reducing the degree of amplification is expected to improve sequence coverage and sequencing quality. Amplification may also be reduced by allowing biopsy-derived tissue (or other starting material, such as cancer biopsies or needle aspirates, fetal or cancer cells isolated from blood flow, etc.) to grow in culture. This approach slightly increases the overall turnaround time of the process. However, high fidelity 'amplification' of genomic DNA during the cultivation of small numbers of cells available to cause chromosomal replication. Because DMPK mutations are a trinucleotide repeat disease, it is difficult to analyze the mutations using current sequencing methods that read results using a pair of partners that are approximately 400bp long. Longer mate pair reads (e.g., 1 kilobase or longer) can be used to span and thus sequence between these regions, which results in an accurate determination of repeat size. Example 3: clinically accurate genome sequencing and haplotype determination from 10-20 human cells In this example, 65-130pg (10-20 cells) of long human genomic DNA (50% of length 60-500kb) was divided into 384 aliquots, amplified, fragmented, and tagged in each aliquot. After sequencing, diploid (phased) genomes were assembled without isolation of DNA clones or mid-stage chromosomes. 10 LFR pools were used to generate approximately 3.3 terabase (Tb) positional reads from 7 unique genomes. Up to 97% of the heterozygous Single Nucleotide Variants (SNV) were assembled into contigs with 50% of the covering bases (N50) in contigs longer than about 500kb (for European ethnic samples) and about 1Mb (for African samples). In extensive comparisons between duplicate libraries, LFR haplotypes were found to be highly accurate with 1 false positive SNV per 10 megabases (Mb). This 20-30 fold increase in accuracy compared to the non-LFR genome was achieved despite starting with 100 picograms (pg) of DNA and 10,000 fold in vitro amplification (Drmanac et al, Science 327:78,2010; Roach et al, am.J.hum.Genet.89: 382. sup. 397,2011) because most of the errors are not consistent with the true haplotype. We have demonstrated cost-effective and clinically accurate genome sequencing and haplotype determination from 10-20 individual cells. The LFR technique is a cost-effective DNA pre-treatment step without cloning or metaphase chromosome segregation, which allows for complete sequencing and assembly of different parent chromosomes at clinically relevant costs and scale. LFR can be adapted to be used as a pre-treatment step prior to any sequencing method, although we employ short read sequencing techniques, as described in detail above. LFR can produce long range phased SNPs because it is conceptually similar to single molecule sequencing of fragments that are 10-1000kb in length. This is achieved by randomly dividing the corresponding parental DNA fragments into physically distinct pools without any DNA cloning steps, followed by fragmentation to generate shorter fragments (similar to aliquots of fosmid clones (Kitzman et al, nat. biotechnol.29:59-63,2011; Suk et al, Genome res.21: 1672-. As the fraction of the genome in each set is reduced to less than a haploid genome, the statistical probability of having corresponding segments from two parent chromosomes in the same set is significantly reduced. Likewise, the more individual pools interrogated, the greater the number of times fragments from maternal and paternal homologs will be analyzed in different pools. For example, a 384 well plate with 0.1 genome equivalents per well yields a theoretical 19x coverage of both maternal and paternal alleles of each fragment. Such a high initial DNA redundancy ratio of about 19x results in more complete Genome coverage and higher variant response and phasing accuracy using the strategy employing a fosmid set, which results in coverage ranging from about 3x (Kitzman et al, nat. biotechnol29:59-63,2011) to about 6x (Suk et al, Genome res.21: 1672-. To prepare LFR libraries in a high throughput manner, we developed an automated method that performed all LFR-specific steps in the same 384-well plate. The following is a summary of the process. First, highly consistent amplification was performed using a modified phi 29-based multiplex displacement amplification (MDA; Dean et al, Proc. Natl. Acad. Sci. U.S.A.99:5261,2002) to replicate each fragment about 10,000-fold. Next, the DNA is fragmented and ligated to barcode adaptors via an enzymatic step process within each well without an intervening purification step. Briefly, long DNA molecules were processed into blunt-ended 300-and 1,500bp fragments by controlled random enzymatic fragmentation (CoRE). The CoRE fragmented the DNA via removal of uridine bases, which were incorporated at a predetermined frequency during MDA by uracil DNA glycosylase and endonuclease IV. Nick translation from the resulting single base nicks with E.coli polymerase 1 resolved the fragments and produced blunt ends. Then, unique 10-base Reed-Solomon error correcting barcode adaptors (PCT/US2010/023083, published as WO 2010/091107, incorporated herein by reference), designed to reduce any preference caused by sequence and concentration differences of each barcode (fig. 18), were ligated to fragment the DNA in each well using a high-yield, low-chimera formation protocol (Drmanac et al, Science 327:78,2010). Finally, all 384 wells were combined and the unsaturated polymerase chain reaction was employed using primers common to the ligation adaptors to generate templates sufficient for short read sequencing platforms. More details on the LFR scheme we employ are provided below. High molecular weight DNA was purified from cell lines GM12877, GM12878, GM12885, GM12886, GM12891, GM12892 GM19240, and GM20431(Coriell Institute for Medical Research, Camden, NJ) using a RecoverEase DNA isolation kit (Agilent, La Jolla, CA) following the manufacturer's protocol. High molecular weight DNA was partially sheared to make it more suitable for manipulation by pipetting 20-40 times using a Rainin P1000 pipette. 200ng of genomic DNA was analysed on a 1% agarose gel with 0.5 XTBE buffer using BioRad CHEF-DR II with the following parameters: 6V/cm,50-90 second ramp transition time and 20 hours total run. The length of the purified genomic DNA was determined using 500ng of yeast chromosomal PFG marker (New England Biolabs, Ipshow, MA) and Lambda Ladder PFG marker (New England Biolabs, Ipshow, MA). In addition, the immortalized cell line GM19240(Coriell Institute for Medical Research, Camden, NJ) was cultured in RPMI supplemented with 10% FBS under standard environmental conditions for cell culture. Individual cells were detached at 200-fold magnification using a micromanipulator (Eppendorf, Hamburg, Germany) and placed in 1.5ml microtubes with 10ul dH 2O. Cells were denatured with 1ul of 20mM KOH and 0.5mM EDTA. The denatured cells are then allowed to enter the LFR process. DNA from each of the multiple cell lines was diluted and denatured at a concentration of 50pg/ul in a solution of 20mM KOH and 0.5mM EDTA. After 1 min incubation at room temperature, 120pg of denatured DNA was removed and added to 32ul of 1mM 3' thiol-protected random octamer (IDT, Coralville, IA). After 2 minutes, the mixture was brought to a volume of 400ul with dH2O and 1ul was dispensed into each well of a 384 well plate. Mu.l of a 2X phi29 polymerase (enzymics Inc., Beverly, Mass.) based Multiple Displacement Amplification (MDA) mix was added to each well to generate approximately 3-10 nanograms of DNA (10,000 to 25,000 fold amplification). The MDA reaction consisted of 50mM Tris-HCl (pH 7.5),10mM MgCl2,10mM (NH4)2SO4,4mM DTT,250uM dNTP (USB, Cleveland, OH),10uM 2 '-deoxyuridine 5' -triphosphate (dUTP) (USB, Cleveland, OH), and 0.25 units phi29 polymerase. Then, controlled random enzymatic fragmentation (CoRE) was performed. Excess nucleotides were inactivated and uracil bases were removed by reacting MDA with a mixture of 0.031 units of Shrimp Alkaline Phosphatase (SAP) (USB, Cleveland, OH), 0.039 units of uracil DNA glycosylase (New England Biolabs, Ipswich, MA) and 0.078 units of endonuclease IV (New England Biolabs, Ipswich, MA) for 120 minutes at 37 ℃. SAP was heat-inactivated at 65 ℃ for 15 minutes. Nicks were resolved in the same buffer with 0.1 nanomole dNTP (USB, Cleveland, OH) addition using a 60 minute room temperature nick translation of 0.1 unit E.coli DNA polymerase 1(New England Biolabs, Ipswich, Mass.) and DNA fragmentation into 300-base pair 1,300 fragments. Coli DNA polymerase 1 was heat inactivated at 65 ℃ for 10 min. The remaining 5' phosphate was removed by incubation with 0.031 units of SAP (USB, Cleveland, OH) for 60 minutes at 37 ℃. SAP was heat-inactivated at 65 ℃ for 15 minutes. Then, tagged adaptor ligation and nick translation are performed. A 10 base DNA barcode adaptor (unique for each well) was attached to the fragmented DNA using a two-part directed ligation method. Approximately 0.03pmol of fragmented MDA product was incubated for 4 hours at room temperature in a reaction containing 50mM Tris-HCl (pH 7.8), 2.5% PEG 8000,10mM MgCl2,1mM rATP,100 fold molar excess of 5 '-phosphorylated (5' PO4) and 3 'dideoxy-terminated (3' dd) common Ad1 (FIG. 18) and 75 units of T4 DNA ligase (Enzymatics, Beverly, Mass.) in a total volume of 7 ul. Ad1 contains common overhang regions for ligation and hybridization with unique barcode adaptors. After 4 hours, a 200-fold molar excess of unique 5' phosphorylated tagged adaptors was added to each well and allowed to incubate for 16 hours. The 384 well groups were combined to a total volume of about 2.5ml and purified by addition of 2.5ml of AMPure beads (Beckman-Coulter, Brea, CA.). One round of PCR was performed to create molecules with 5 'adaptors and tags on one side and 3' blunt ends on the other side. As described above, the 3 'adaptor is added in a ligation reaction similar to the 5' adaptor. To seal the nicks created by ligation, the DNA was incubated in a reaction containing 0.33uM Ad1 PCR1 primer, 10mM Tris-HCl (pH 78.3), 50mM KCl, 1.5mM MgCl2,1mM rATP,100 uM dNTP for 5 minutes at 60 ℃ to exchange the 3 'dideoxy-terminated Ad1 oligomer with the 3' -OH-terminated Ad1 PCR1 primer. The reaction was then cooled to 37 ℃ and incubated for an additional 30 minutes at 37 ℃ after addition of 90 units of Taq DNA polymerase (New England Biolabs, Ipswich, MA) and 21600 units of T4 DNA ligase to create a functional 5 '-PO 4gDNA end from the Ad1 PCR1 primer 3' -OH end by Taq-catalyzed nick translation and to seal the resulting repair nicks by T4 DNA ligation. At this point, the material was incorporated into standard DNA nano-array sequencing methods. Starting from total RNA, RNA-Seq data were obtained using the Ovation RNA-Seq kit (NuGen, San Carlos, Calif.) and SPRIWork (Beckman-Coulter, Brea, Calif.) to prepare a sequencing library with an average insert size of 150-200 bp. 75bp paired-end sequencing reactions were performed at the Personalized Genetic Medicine Center (Center for Personalized Genetic Medicine) (Harvard Medical School, Boston, Mass.) on HiSeq 2000(Illumina, San Diego, Calif.). Paired end reads were assembled with tophat v1.2.0(Trapnell et al, Bioinformatics 25: 1105-type 1111,2009) using bowtie v0.12.7(Langmead et al, Genome biol.10: R25,2009) and responded to Single Nucleotide Variants (SNV) using a GATK UnifiedGenottyper v1.1(http:// www.broadinstitute.org/gsa/wiki/index. php/GATK _ release _1.1) with reference to dbSNP, 132 th edition with hg19 and annotation of known SNPs. SNV is also mapped to genes from RefSeq and isoforms in the transcriptome as identified by cufflinks v1.0.3(http:// cufflinks. cbcb. umd. edu/tutoral. html). To identify haplotypes of co-expressed alleles, data is filtered for heterozygous SNVs that occur simultaneously on the same LFR contig and on the same gene with at least one other heterozygous SNV. In the case where the transcript exhibits allele-specific expression, the heterozygous alleles expressed on the LFR phased haplotype should all have a higher, or all have a lower read count than their counterparts on the other haplotype. Here, we identified the more highly expressed haplotype as the haplotype for which most of their heterozygous alleles exhibited higher expression than their counterparts. A heterozygous is calculated to be 'consistent' if its expression is consistent with the haplotype it contains. In the case of bisection (where there is no haplotype majority), half of the heterozygous SNVs were calculated to be consistent. In addition, to be fully considered, it is desirable that heterozygous SNVs have at least 20-fold RNA-Seq read coverage. Heterozygous SNVs were further filtered for noise from the GATK genotype determinator (genotyper) by randomly using a binomial test in comparison to the probability of selecting ASE and coverage. For error correction purposes, each DNB is tagged with a 10 base Reed-Solomon code with either a1 base error correction capability for unknown error positions or a 2 base error correction capability at known error positions (U.S. patent application 12/697,995, published as US2010/0199155, which is incorporated herein by reference). The 384 codes are selected from a comprehensive set of 4096 Reed-Solomon codes having the characteristics described above (U.S. patent application 12/697,995, which is incorporated herein by reference). Each code from this group has a minimum hamming distance of 3 from any other code in the group. For this study, it was assumed that the error location was unknown. Results. To demonstrate the ability of LFR to determine the exact diploid genomic sequence, we generated three pools of approximately luba female HapMap samples NA 19240. NA19240 was extensively interrogated as part of a triplet of the HapMap Project (Consortium, Nature 437: 1299-. Thus, based on redundant sequence data of parental samples NA19238 and NA19239, correlations can be generated Highly accurate haplotype information at 170 ten thousand heterozygous SNPs. Starting with 10 cells (65pg DNA) of the corresponding immortalized B cell line, 1 NA19240 LFR pool was generated. Based on the total valid reads covering 60x and using 384 unique fragment aliquots or pools, we estimated that if the DNA was denatured prior to distribution into wells (20 cell equivalents of dsDNA; table 1 below), the optimal number of starting cells would be 10. From the estimated 100-130pg (15-20 cell equivalents) denaturation of high molecular weight genomic DNA to generate 2 repeat libraries. It was determined that the optimal amount per pool would be about 100pg, starting from denatured isolated DNA. This amount was chosen to achieve more consistent genome coverage by minimizing random sampling of samples. All three pools were analyzed using DNA nanoarray sequencing (Drmanac et al, Science 327:78-81,2010). The 35 base mate pair reads were mapped to the reference genome using a custom alignment algorithm (Drmanac et al, Science 327:78-81,2010; Carnevali et al, J.computational biol.,19,2011), yielding on average over 230Gb mapping data with an average genome coverage of greater than 80 × (Table 1, below). Analysis of the localized LFR data showed 2 unique features attributable to MDA: slight under-representation of the GC-rich sequence (fig. 19) and an increase in the chimeric sequence. In addition, the coverage normalized between 100kb windows is about 2-fold more variable. However, almost all genomic regions are covered with sufficient reads (5 or more), indicating that 10,000-fold MDA amplification by our optimization protocol can be used for comprehensive genomic sequencing. The barcode is used to locate the reads in a graphical grouping based on their physical hole locations within each library (which display overlaid pulses, i.e., overlaid sparse areas spread across long spans with little read coverage). On average each well contained 10-20% of the haploid genome (300-600Mb) in fragments ranging in length from 10kb to over 300kb, with N50 being about 60kb (FIG. 20). Initial fragment coverage is very consistent across chromosomes. The total amount of DNA actually used to generate the two libraries from the extracted DNA was about 62pg and 84pg (9.4 and 12.7 cell equivalents, fig. 20) as assessed from all the test fragments. This is less than the expected 100-130pg, indicating some loss or undetectable DNA or imprecision in DNA quantification. Interestingly, the library of 10 cells appeared to be generated from about 90pg (13.6 cells) of DNA, most likely due to some cells being in S phase during isolation (fig. 20). Overlapping heterozygous SNPs from fragments of the same parental chromosome located in different wells were assembled into haplotype contigs using a two-step custom genotyping algorithm designed to interrogate low coverage read result data (less than 2x coverage) from approximately 40 individual wells (figure 21). Unlike other experimental methods (Kitzman et al, nat. Biotechnol.29:59-63,2011; Suk et al, Genome Res.21: 1672-. Instead, LFR ensures complete presentation of the genome by maximizing DNA fragment input in terms of number of aliquots and coverage of a given read. In the first step, heterozygous SNPs from unphased NA19240 genome assembly (www.completegenomics.com/sequence-data/download-data /) were combined with each LFR pool to create a comprehensive SNP panel for phasing. Next, a network is constructed for each chromosome, where nodes correspond to heterozygous SNP responses, and connections involve connectivity scores between each pair of SNPs. Along with the ligation scores, directions were also obtained as part of searching for the best hypothesis for each pair of heterozygous SNPs. This highly redundant sparse-connected network is then trimmed using domain knowledge, followed by optimization using Kruskal's Minimum Spanning Tree (MST) algorithm. This resulted in a longer contig from which 950-1200kb N50 was obtained (FIG. 20). A total of about 240 million heterozygous SNPs were phased in each library by LFR (figure 20). LFR phasing is expected to step through approximately 90% of the heterozygous SNPs for these libraries. Library phasing of 10 cells over 98% of the two library phased variants generated from isolated DNA demonstrated the potential of LFR to function with a small number of isolated cells. Doubling the number of reads to about 160x coverage further increased the number of phased heterozygous SNPs to over 258 million, thereby increasing the phasing rate to 96% (fig. 20). Combining repeats 1 and 2 (768 individual wells in total), each with 80x coverage, yielded over 265 ten thousand phased heterozygous SNPs, and yielded 97% phasing rate. Using only the responding SNP loci in the phasing LFR library (omitting step 1 of the LFR algorithm) typically results in a 5-15% reduction in the total number of phasing SNPs (fig. 20). Importantly, the number of phased SNPs obtained by LFR alone (starting only from 10-20 cells of DNA) is slightly higher than the number of SNPs phased by the current fosmid method (Kitzman et al, Nat. Biotechnol.29:59-63,2011; Suk et al, Genome Res.21: 1672-. This is substantially more than 81% of heterozygous SNPs that can be phased using standard parental sequences (Roach et al, am.j.hum.genet.89: 382-cell 397,2011) due to the larger fraction of variants in parents sharing children. Adding parental-derived haplotype data to the 768-well library improved the phasing rate to 98%. About 115,000 (about 4%) phased heterozygous SNPs are from a high coverage LFR library and are not responded to in the standard library, indicating that MDA amplification and 160x coverage contribute to some regions with reads (5 or more) sufficient to respond correctly. The high coverage LFR phasing ratio can be adjusted to balance haplotype integrity versus phasing error. Haplotype determination of European lineage. To further understand the performance of LFR, we generated additional libraries from european ancestral pedigrees. The CEPH family 1463 was chosen because it has three generations of individuals, allowing a thorough study of genetics. This family has been previously studied as part of the public data release (www.completegenomics.com/sequence-data/download-data /). Libraries were generated from individuals of each generation. A total of more than 1.6Tb sequence data was generated for NA12877, NA12885, NA12886, NA12891, and NA 12892. Generally, phasing was very high among all samples with about 92% of the attempted SNPs phased into the contig (fig. 20). Combining two LFR libraries (fig. 20) or LFR with parental-based phasing improved the overall ratio of phased SNPs to 97%. The N50 contig length between all analyzed family members was 500-600 kb. This length is limited to a length below NA 19240. Investigation of the distribution of SNPs among the genomes of several different populations explains this difference. Origin of low heterozygosity regions in African populationsAnd influence of. The previously reported relative excess of pure zygotes in non-African ethnicity was clarified in the European lineage samples by about two-fold more low heterozygosity regions of 30kb-3Mb (RLH, defined as a 30kb genomic region with less than 1.4 heterozygous SNPs per 10kb, about 7-fold lower than the planting density) than in NA19240 (Gibson et al, hum. mol. Genet.15: 789-K795, 2006; Lohmueler et al, Nature 451: 994-K997, 2008) and further supported by analysis of 52 whole genomes (Nicholas Schork, personal communications). These regions are obstacles to phasing, resulting in twice as little N50 contig length. More than 90% of the contigs in the european genome end up with these RLHs varying among unrelated individuals. About 3% of all heterozygous SNPs in the african genome (30-60% of all non-phased heterozygous SNPs) belong to these RLHs, covering a very large fraction (30-40%) of these genomes. In the genome of Chinese and European countries, the longer RLH clustered around 45 heterozygous SNPs per Mb (genome coverage was about 1000 per Mb outside RLH), indicating that they shared a common ancestor around 43,000 years ago (mutation rate based on 60-70 SNPs per 20 years generation; Roach et al, Science328: 636-. This may be due to a strong bottleneck at or after the time of departure of humans from Africa and within a previously established range 10,000 years ago 65,000 (Li and Durbin, Nature 475: 493-. Furthermore, an excess of RLH was observed on the X chromosome in european and indian women (NA12885, NA12892 and NA20847) when compared to african women (NA19240), covering about 50% versus 17% of this chromosome (30% versus 14% for the entire genome in these same individuals), respectively. This indicates an even stronger departure from Africa (out-of-Africa) bottleneck in the X chromosome. A possible explanation is that substantially fewer women remain in africa and have offspring with multiple men. These observations suggest that analysis of whole genome variation in thousands of diverse genomes, including haplotype determination, will provide a profound understanding of human population genetics and the impact of these extensive 'inbred' regions (which each typically contain more than 100 homozygous variants) on human disease and other extreme phenotypes. In addition, it showed that about 2,000 RLHs greater than 100kb in length would be present in all African individuals. Populations with a limited number of high frequency haplotypes, which may originate from recent bottleneck or inbred breeding (Gibson et al, hum. mol. genet.15: 789-. As such, population history and some reproductive modalities can make phasing challenging, as exhibited by the X chromosome of non-african females. Regardless of these factors, LFR phasing performance was roughly equivalent, phasing up to 97% of heterozygous SNPs in both european and african individuals, the outcome of which should be transformed among all populations. In addition to standard genotyping as described below that combines LFR with a parent (which may be more limited to some families of strategies, as discussed above), the use of initial DNA fragments longer than 300kb (e.g.by trapping cells or pre-purified DNA in gel blocks (Cook, EMBO J.3: 1837. 1842,1984)) will span about 95% of all RLHs and haplotype for most of the re-mutations that occur in these regions. This would not be feasible with the current fosmid cloning strategy (Kitzman et al, nat. Biotechnol.29:59-63,2011; Suk et al, Genome Res.21: 1672-. LFR reproducibility and phasing error rate analysis. In an effort to understand the reproducibility of LFR, we compared haplotype data between two NA19240 duplicate libraries. Typically, the libraries were very identical, with the two libraries only accounting for 64 differences per library in about 220 ten thousand heterozygous SNPs (fig. 22). This represents 1 error in phasing error rate of 0.003% or 44 Mb. LFR is also highly accurate when compared to conserved but accurate whole chromosome phasing resulting from parental genomes NA19238 and NA19239 previously sequenced by multiple methods. Only about 60 cases of 157 million equivalent single loci were found with LFR phasing of variants that did not agree with the variants determined for the parental haplotypes (assuming a phase rate of 0.002% if half of the inconsistency was due to sequencing errors in the parental genomes). The LFR data also contained about 135 contigs (2.2%) per library with one or more flipped haplotype blocks (fig. 22). Will make theseAnalysis of european repeated libraries extending to sample NA12877 (fig. 22) and comparing them to a family-based high quality analysis (Roach et al, am.j.hum.genet.89: 382. sup. and. sup. 397,2011) recently performed with 4 children using NA12877 and their mother NA12878 yielded similar results assuming that each method contributed half of the observed inconsistencies. In both NA19240 and NA12877 libraries, several contigs had many inverted segments. Most of these contigs tend to be located in Regions of Low Heterozygosity (RLH), low read coverage, or repetitive regions observed in an unexpectedly large number of wells (e.g., subtelomeric or centromeric regions). Grouping haplotype contigs into parental chromosomes. Most of the flip errors can be corrected by imposing an LFR phasing algorithm on the end contigs in these regions. Alternatively, these errors can be removed by a simple, low-cost addition of standard high-density array genotype data (about 100 ten thousand or more SNPs) from at least one parent to the LFR assembly. In addition, we found that the parental genotypes can be linked to 98% LFR phased heterozygous SNPs across the whole chromosome. In addition, this data allows for the assignment of haplotypes to both maternal and paternal lineages, information that can be used to incorporate parental imprints in genetic diagnosis. If no parental data is available, population genotype data can also be used to link LFR contigs between whole chromosomes, although this approach can increase phasing errors (Browning and Browning, nat. Rev. Genet.12:703-714, 2011). Even technically challenging approaches such as metaphase chromosome segregation (which has demonstrated whole chromosome haplotyping) cannot assign parental origin without some form of parental genotype data (Fan et al, nat. biotechnol.29:51-57,2011). This combination of two simple techniques (i.e., LFR and parental genotype determination) provides an accurate, complete, and annotated haplotype at low cost. Phased reoccurring mutation. As a demonstration of the completeness and accuracy of our diploid genome sequencing, we evaluated the phasing of the 35 re-mutations recently reported in the NA19240 genome (Conrad et al, nat. Genet.43: 712-. 34 of these mutations are in a standard genome orResponse in one of the LFR libraries. Of those, 32 re-mutations were phased in at least one of the two repeat LFR libraries (16 from each parent). Not surprisingly, the two non-phased variants resided in RLH. Of these 32 variants, 21 were phased by Conrad et al (supra), and 18 were consistent with LFR phasing results. Three inconsistencies may be due to errors in previous studies (Matthew Hurles personal communications), confirming LFR accuracy, without affecting the essential conclusions of the report. Genomic sequencing and haplotyping from 100pg DNA using only LFR libraries. The analysis described above incorporated heterozygous SNPs from both standard and LFR libraries. However, it is possible to use only the LFR library, given the complete presentation of the genome that would be expected by starting with an amount of DNA equivalent to that present in 10-20 cells. We have demonstrated that MDA provides sufficiently consistent amplification and with high (80x) overall read coverage, the LFR library taken alone allows detection of up to 93% heterozygous SNPs without any modification to our standard library variation-response algorithm. To demonstrate the potential of using only LFR libraries, we phased NA19240 repeat 1 and an additional 250Gb read from the same library (500 Gb total). We observed a 15% and 5% reduction in the total number of phased SNPs, respectively (fig. 20). This result was not surprising given that this library was generated from 60pg DNA instead of the optimal amount of 200pg (table 1 below) and also given the previously mentioned GC preferences incorporated during in vitro amplification by MDA. Another 285Gb LFR library responded and phased only 90% of all variants from the combined standard and LFR library (fig. 20). Despite the reduction in phased total SNPs, contig length was largely unaffected (N50) >1Mb)。 Error reduction by LFR for accurate genome sequencing from 10 cells. Substantial error correction (about 1 SNV out of 1,000 kilobases of response 100) is a common attribute of all current massively parallel sequencing techniques. These ratios can be too high for diagnostic use and they complicate many studies to search for new mutations. The vast majority of false positive variations are no longer likely to occur on either the maternal or paternal chromosomes. LFR mayTo take advantage of this lack of consistent connectivity with the surrounding true variation to eliminate these errors from the finally assembled haplotype. The joluba triplet and european pedigree both provide excellent platforms for demonstrating the error reducing ability of LFR. We defined a set of heterozygous SNPs in NA19240 and NA12877 (greater than 85% of all heterozygous SNPs) that were reported with high confidence in each individual parent as matching the reference genome on both alleles. There are approximately 44,000 heterozygous SNPs in NA19240 and 30,000 in NA12877 that meet this criteria. These variations are, by virtue of their absence in the parental genome, re-mutations, cell line-specific somatic mutations, or false-positive variants. Approximately 1,000-1,500 of these variants were reproducibly phased in each of two replicate libraries from samples NA19240 and NA12877 (fig. 23). These numbers are similar to those reported for the reassociation cell line-specific mutations in NA19240 (Conrad et al, nat. Genet.43:712-714, 2011). The remaining variants were likely initial false positives, with only about 500 phasing per library. This represents a 60-fold reduction in false positive rate in those variations of phasing. Only about 2,400 of these false variants were present in the standard library, of which only about 260 were found (less than 1 false positive SNV in 20 Mb; 5700 haploid Mb/260 errors). Each LFR library exhibited a phased 15-fold increase in library-specific false positive responses as compared to the genome sequenced by standard methods. Most of these false positive SNVs may have been introduced by MDA; sampling of rare cell line variants can result in a smaller percentage. Despite the large amount of error introduced by generating LFR libraries from 100pg DNA and amplifying via MDA, applying the LFR phasing algorithm reduces the overall sequencing error rate to 99.99999% (about 600 pseudoheterozygous SNV/6Gb), i.e., about 10-fold lower than that observed using the same ligation-based sequencing chemistry (Roach et al, am.J.Human Genet.89:382-397, 2011). Improving base response with LFR information. In addition to phasing and elimination of false positive heterozygous SNVs, LFR can 'rescue' or 'non-responsive' locations or verify other responses (e.g., homozygous reference or homozygous variants) by evaluating the pore origins that support reads for each base response. As a certificateClearly, we found no response in the genome of NA19240 repeat 1, but a position adjacent to the proximally phased heterozygous SNP. In these examples, the positions can be 're-responded' because phased heterozygous SNPs do target the presence of a shared pore between adjacent phased SNPs and non-responsive positions (fig. 24). While LFRs may not be able to rescue all non-responsive locations, this simple demonstration highlights the usefulness of LFRs in responding more precisely to all genomic locations to reduce non-responsiveness. Highly divergent haplotypes found in the African and non-African genomes. Haplotype analysis by large-scale genotyping studies such as the HapMap project is very important to understanding population genetics. However, the resolution of an individual's complete haplotype is largely intractable or prohibitively expensive. A highly accurate haplotype (filtering out clustered pseudo-heterozygotes that accumulate due to the putative position of the repeat region) (Li and Durbin, Nature 475: 493-. As a demonstration, we scanned LFR contigs of NA19240 for high divergence regions between the female and male parent copies. Identifying 7000 10-kb regions containing more than 33 SNVs; an increase of 3 fold over the expected 10 SNVs. Given 0.1% sustained variation (stabilizing variation) and 0.15% base difference every 100 million years (based on 1% divergence of the human and chimpanzee genomes evolved about 600 million years from a common ancestor), our calculations suggest that about 50Mb (about 2.0% of the 'non-inbred' genomes) in these regions found in this african genome may have evolved separately for over 150 million years. This estimate is closer to 1Myr if chimpanzee-human separation is less than 500 million years ago (Hobolth et al, Genome Res.21:349-356, 2011). This whole genome analysis is consistent with the current study by Hammer et al of several targeted genomic regions in african populations (assuming possible heterosis (internberfeeding) of different races of africa) (proc. natl. acad. sci. u.s.a.108: 15123-. Our analysis showed that 2.1% of european african inbred genomes also have similarly divergent sequences, usually at different genomic locations. Most of these may be left in africa in humans And introducing. A single genome contains multiple genes with inactivating variations in both alleles. A highly accurate diploid genome is essential to make human genome sequencing valuable to the clinical setting. To demonstrate how LFR can be used in a diagnostic/prognostic setting, our NA19240 encoded SNP data was analyzed for nonsense and splice site disruption variations. We further analyzed all missense variations using PolyPhen2(Adzhubei et al, nat. methods7:248-249,2010) to select only those that encoded unfavorable variations. Both 'potentially damaging' and 'presumably damaging' are considered to be detrimental to protein function, as both are nonsense mutations. 3485 variants matched these criteria. After phasing and removal of false positives, only 1252 variants remained; i.e. an important reduction of potentially misleading information. We further reduced the list to examine only those 316 heterozygous variants, at least two of which co-occur in the same gene. Using phasing data, we were able to identify 189 variants present in the same allele within 79 genes. The remaining 127 SNPs were found to be scattered among 47 genes with at least one adverse variation in each allele (fig. 25). This number was increased to 65 genes by haplotype determination on NA19240 by combining two LFR libraries. This analysis was extended to european pedigree demonstrating that a similar number of genes (32-49 with coding mutations in both alleles) potentially changed to a point where little to no effective protein product was expressed (fig. 25). Variants extending this analysis to the disrupted Transcription Factor Binding Site (TFBS) introduce an additional approximately 100 genes per individual. Many of these may be partial or no loss of functional change. Due to the high accuracy of LFR, it is unlikely that these variants are the result of sequencing errors. Many of the discovered adverse mutations may have been introduced in the propagation of these cell lines. A few of these genes were found in unrelated individuals suggesting that they may be the result of incorrect annotation or systematic localization or reference errors. The genome of NA19240 contains an additional about 10 genes in the complete loss of functional species; this is most likely due to the preferences introduced by annotating the african genome with the european reference genome. Is not limited to These numbers, however, are consistent with those found in several current studies on phased individual genomes (Suk et al, Genome Res.21: 1672-. We have demonstrated that LFR can place SNPs into haplotypes within a large genomic distance, where the phase of those SNPs can cause a potentially complete loss of function to occur. Such information can be crucial for effective clinical interpretation of the patient genome and for carrier screening. Disruption of TFBS linked to differences in allelic expression. Long haplotype coverage of both cis-regulatory region and coding sequence is crucial to understanding and predicting the expression level of each allele of a gene. By analyzing 5.6Gb non-exhaustive expression data from RNA sequencing of NA20431 lymphocytes, we identified a small number of genes with significant differences in allele expression. In each of these genes, SNV was scanned for the 5kb regulatory region upstream and 1kb downstream of the transcriptional initiation checkpoint and significantly altered the binding sites for over 300 different transcription factors (Sandelin et al, 32: D91-D94,2004). In six cases (FIG. 26), 1-3 bases between the two alleles were found to differ in each gene, causing significant effects on one or more putative binding sites and potentially accounting for the differential expression observed between alleles. Although this is only one data set and it is currently unclear how much these changes have an effect on transcription factor binding, these results demonstrate that by virtue of this type of large scale study (Rozowsky et al, mol. Syst. biol.7:522,2011), it becomes possible to elucidate the consequences of sequence changes to transcription factor binding sites using LFR haplotyping. Discussion of the related Art. We have demonstrated the ability of LFR to accurately phase up to 97% of all detected heterozygous SNPs in the genome into a long continuous segment of DNA (N50 of 400-1500kb in length). Even LFR libraries that are phased only with 10-20 individual cells, without candidate heterozygous SNPs from a standard library, and thus are able to phase 85-94%Despite the limitations of current implementations. In several cases, the LFR library used in this article has less than optimal starting input DNA (e.g., NA 20431). Consistent with this conclusion is the improvement in phasing rates seen by combining two duplicate libraries (samples NA19240 and NA12877) or starting with more DNA (NA 12892). In addition, insufficient presentation of GC-rich sequences resulted in fewer genomes (90-93% versus greater than 96% (for the standard library)) of the response. Improvements to the MDA method (e.g. by adding region-specific primers or by improving yield in other steps with less amplification) or the way we implement base and variant responses in LFR libraries (possibly by using the read results for well allocation) would help to increase coverage in these regions. Furthermore, as the cost of whole genome sequencing continues to decline, higher coverage libraries (which significantly improve response rates and phasing) may become more affordable. Consensus haploid sequences are sufficient for many applications; however, it lacks two very important parts of data on personalized genomes: identification of phased heterozygous variants and false positive and negative variant responses. One of the goals of the personal genome is to detect the disease causing the variant and to be extremely confident in determining whether an individual carries such a variant or has one or two unaffected alleles. By independently providing sequence information from both maternal and paternal chromosomes, LFR is able to detect regions in a genomic assembly that have covered only one allele. Likewise, false positive responses are avoided because LFR sequences both maternal and paternal chromosomes independently 10-20 times in different aliquots. The result is a statistically low probability that random sequence errors will occur repeatedly in several aliquots at the same base position on one parent allele. Thus, LFR for the first time allows for both accurate and cost-effective sequencing of genomes from a small number (preferably 10-20) of human cells, despite the use of in vitro DNA amplification and the resulting large inevitable polymerase errors. Furthermore, by phasing SNPs over hundreds of kilobases to many megabases (or by conventional genotyping assays that integrate LFRs with one or two parents throughout the chromosome), LFRs can more accurately predict the effect of complex regulatory variants and parental imprints on allele-specific gene expression and function in multiple tissue types. In summary, this provides a highly accurate report on potential genomic changes that can cause gain or loss of protein function. It can be critical that such information obtained inexpensively for each patient be below clinical use of genomic data. Furthermore, successful and affordable diploid sequencing of the human genome starting from 10 cells opens the possibility of comprehensive and accurate genetic screening from a wide variety of tissue sources, such as circulating tumor cells or micro-biopsies of pre-implantation embryos generated via in vitro fertilization. While the present invention is satisfied by embodiments in many different forms, as described in detail in connection with preferred embodiments of the invention, it is to be understood that the present disclosure is to be considered as illustrative of the principles of the invention and is not intended to limit the invention to the specific embodiments illustrated and described herein. Many variations may be made by those skilled in the art without departing from the spirit of the invention. The scope of the invention is to be measured by the appended claims and their equivalents. The abstract and title of the invention should not be construed as limiting the scope of the invention, since the intention is to enable a suitable authority and the general public to quickly ascertain the general nature of the invention. In the appended claims, unless the term 'means' is used, wherein a recited feature or element should not be construed as belonging to 35 u.s.c. § 112,6 means plus function limitations. The present invention provides the following: 1. a method of determining the sequence of a complex nucleic acid of one or more organisms, the method comprising: (a) receiving, on one or more computing devices, a plurality of reads of the complex nucleic acid; and are (b) Generating, with the one or more computing devices, an assembled sequence (assembled sequence) of the complex nucleic acid from the reads, the assembled sequence comprising less than 1 false single nucleotide variant per megabase at a response rate (call rate) of 70% or greater. 2. The method of clause 1, further comprising identifying a plurality of sequence variants in the assembled sequence and phasing (phase) the plurality of sequence variants to produce a phased sequence. 3. The method of clause 2, comprising phasing at least three of the sequence variants and identifying as an error (error) a sequence variant that is inconsistent with the phasing of at least two sequence variants. 4. The method of clause 2, wherein the assembled sequence is a whole genome sequence, the method comprising phasing at least 70% of the sequence variants. 5. The method of clause 2, wherein the assembled sequence is a whole genome sequence, the method comprising phasing at least 80% of the sequence variants. 6. The method of clause 2, wherein the assembled sequence is a whole genome sequence, the method comprising phasing at least 85% of the sequence variants. 7. The method of clause 2, wherein the assembled sequence is a whole genome sequence, the method comprising phasing at least 90% of the sequence variants. 8. The method of clause 2, wherein the assembled sequence is a whole genome sequence, the method comprising phasing at least 95% of the sequence variants. 9. The method of clause 1, wherein the step of receiving the plurality of reads of the complex nucleic acid is receiving the plurality of reads for each of a plurality of aliquots, each aliquot comprising one or more fragments of the complex nucleic acid. 10. The method of clause 9, which comprises responding to a base at a position in the assembled sequence based on preliminary base responses of two or more aliquots at the position. 11. The method of clause 9, which comprises identifying as true base responses that occur 3 or more times in reads of two or more aliquots. 12. The method of item 9, wherein an aliquot-specific tag is attached to each of said fragments, said method further comprising determining which aliquot gave said reading by identifying said aliquot-specific tags. 13. The method of clause 12, wherein the aliquot-specific tag comprises an error correction code and each read comprises tag sequence data and fragment sequence data, wherein the tag sequence data is correct tag sequence data or incorrect tag sequence data comprising one or more errors; the method further comprises the following steps: (c) correcting the incorrect tag sequence data using the error correction code, thereby producing corrected tag sequence data and uncorrectable tag sequence data; (d) in a first computer method requiring tag sequence data, using a read comprising the correct tag sequence data and the corrected tag sequence data, and generating a first output; and are (e) In a second computer method that does not require tag sequence data, a read result that contains the uncorrectable tag sequence data is used and a second output is generated. 14. The method of item 13, wherein the first computer method is selected from the group consisting of: sample multiplexing, library multiplexing, phasing, and error correction methods using tag sequence data. 15. The method of item 13, wherein the second computer method comprises localization, assembly, and set-based statistics. 16. The method of item 13, wherein the error correction code is a Reed-Solomon code. 17. The method of item 1, wherein the method further comprises: (c) providing a first phased sequence of a region of the complex nucleic acid, the region comprising a short tandem repeat; (d) comparing reads of the first phased sequence of the region with reads of the second phased sequence of the region; and are (e) Based on the comparison, identifying an expansion of the short tandem repeat in one of the first phased sequence or the second phased sequence. 18. The method of clause 1, further comprising obtaining genotype data from at least one parent of the organism and generating the assembled sequence of the complex nucleic acid from the reads and the genotype data of the at least one parent. 19. The method of clause 1, further comprising adding population genotype data and generating an assembled sequence of the complex nucleic acid from the reads and the population genotype data. 20. The method of item 1, further comprising: (c) aligning the plurality of reads of the first region of the complex nucleic acid, thereby creating an overlap between the aligned reads; (d) identifying N heterozygous candidates within the overlap, wherein N is an integer greater than 2; (e) clustering 2 of the N heterozygous candidatesNTo 4NA space or a selected subspace of said space of possibilities, thereby creating a plurality of clusters; (f) identifying two clusters having the highest density, each identified cluster comprising a substantially noiseless center; and are (g) Repeating steps (a) - (d) for one or more additional regions of the complex nucleic acid. 21. The method of clause 1, wherein the assembled sequence comprises less than 0.8 false single nucleotide variants per megabase. 22. The method of clause 1, wherein the assembled sequence comprises less than 0.6 false single nucleotide variants per megabase. 23. The method of clause 1, wherein the assembled sequence comprises less than 0.4 false single nucleotide variants per megabase. 24. The method of clause 1, wherein the assembled sequence comprises less than 0.2 false single nucleotide variants per megabase. 25. The method of clause 1, wherein the assembled sequence comprises less than 0.1 false single nucleotide variants per megabase. 26. The method of clause 1, wherein the assembled sequence has a response rate of at least 80% of the complex nucleic acid. 27. The method of clause 1, wherein the assembled sequence has a response rate of at least 85%. 28. The method of clause 1, wherein the assembled sequence has a response rate of at least 90%. 29. The method of item 1, further comprising: (a) providing an amount of the complex nucleic acid, and (b) sequencing the amount of the complex nucleic acid to generate the plurality of reads. 30. The method of item 1, wherein the complex nucleic acid is selected from the group consisting of: genomes, exomes (exosomes), transcriptomes, methylation groups (methylation), mixtures of genomes of different organisms, mixtures of genomes of different cell types of an organism, and subsets thereof. 31. The method of item 1, wherein the organism is a mammal. 32. The method of item 1, wherein the organism is a human. 33. One or more computer-readable non-transitory storage media storing assembled human genome sequences produced by the method of item 1. 34. A computer-readable non-transitory storage medium stores instructions that, when executed by one or more computing devices, cause the one or more computing devices to perform the method of item 1. 35. A method of determining a human genomic sequence, the method comprising: (a) receiving, on one or more computing devices, a plurality of reads of the genome; and are (b) Generating, with the one or more computing devices, an assembled sequence of the genome comprising less than 600 pseudo single nucleotide variants per gigabase at a genome response rate of 70% or greater from the reads. 36. The method of clause 34, wherein the assembled sequence of the human genome comprises a genome response rate of 70% and an exome response rate of 70% or greater. 37. A computer-readable non-transitory storage medium stores instructions that, when executed by one or more computing devices, cause the one or more computing devices to perform the method of item 35. 38. A method of determining a human genomic sequence, the method comprising: (a) receiving, on one or more computing devices, a plurality of reads from each of a plurality of aliquots, each aliquot comprising a fragment of the human genome; and are (b) Generating, with the one or more computing devices, a phased assembled sequence of the genome comprising less than 1000 false single nucleotide variants per gigabase at a genome response rate of 70% or greater from the reads. 39. A computer-readable non-transitory storage medium stores instructions that, when executed by one or more computing devices, cause the one or more computing devices to perform the method of item 38. Sequence listing <110> Coulida genome Ltd (Complete Genomics, Inc.) Drmanac, Radoje Peters, Brock A. Kermani, Bahram G. <120> processing and analysis of Complex nucleic acid sequence data <130> 92171-836153 (5039-US) <140> US 13/448,279 <141> 2012-04-16 <150> US 61/546,516 <151> 2011-10-12 <150> US 61/527,428 <151> 2011-08-25 <150> US 61/517,196 <151> 2011-04-14 <160> 10 <170> PatentIn version 3.5 <210> 1 <211> 20 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 1 ccgcagtagc ttacgaatcg 20 <210> 2 <211> 20 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 2 gatttaactg agcacttggc 20 <210> 3 <211> 10 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 3 aacgagtatt 10 <210> 4 <211> 10 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 4 tttggcgttc 10 <210> 5 <211> 10 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 5 gtagtaccgg 10 <210> 6 <211> 10 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 6 aactgagcgg 10 <210> 7 <211> 12 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 7 cagtcaagtg at 12 <210> 8 <211> 12 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 8 catgatgagg ac 12 <210> 9 <211> 12 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 9 tcttagcatg ta 12 <210> 10 <211> 12 <212> DNA <213> Artificial sequence <220> <223> synthetic polynucleotide <400> 10 gtaactattc ag 12

### Claims

Claims (25) 1. A method of analyzing genomic DNA of an organism, the method comprising: receiving, at one or more computing devices, a plurality of reads corresponding to fragments of genomic DNA from a plurality of aliquots, each fragment of genomic DNA tagged with an aliquot-specific tag sequence, and each read comprising a sequence of a fragment from genomic DNA and an aliquot-specific tag sequence, wherein the genomic DNA contained in each aliquot of the plurality of aliquots is less than a haploid genome equivalent (haploid genome equivalent); Determining an aliquot from which the reads originate by identifying the aliquot-specific tag sequence; generating, with the one or more computing devices, a phased sequence from the reads as follows: identifying a plurality of heterozygous loci corresponding to at least a portion of the organism's genome; and is Phasing the plurality of heterozygous loci to generate a first haplotype and a second haplotype, the phasing using an aliquot of origin of reads corresponding to the plurality of heterozygous loci to determine which alleles at the heterozygous loci are on the same haplotype, the phased sequence corresponding to at least a portion of the genome of the organism, wherein phasing the plurality of heterozygous loci comprises: for each of the plurality of pairs of heterozygous loci, determining a matrix of shared aliquot numbers between alleles on reads at heterozygous loci of the pair, the heterozygous loci of the pair being located within a specified distance of each other. 2. The method of claim 1, wherein phasing the plurality of heterozygous loci further comprises: calculating scores and orientations of corresponding pairs of heterozygous loci using each matrix; and is Determining the first and second haplotypes using the scores and orientations. 3. The method of claim 2, wherein the orientation specifies which allele of the first heterozygous locus of the corresponding pair is linked to the first allele of the second heterozygous locus of the corresponding pair, and wherein the forward orientation specifies that the two alleles are linked as in the list, and the reverse orientation specifies that the two alleles are linked in reverse order of the list. 4. The method of claim 3, wherein a score is calculated for a linkage of a corresponding pair of heterozygous loci, and wherein the calculating comprises: determining a first value for said forward direction; and determining a second value for the reverse direction, wherein the direction is determined based on the greater of the first value and the second value. 5. The method of claim 2, wherein a score is calculated for a linkage of a corresponding pair of heterozygous loci, and wherein the calculating comprises: determining an impurity value which is a ratio of a sum of matrix elements other than the connected two matrix elements to a sum of the matrix elements; and is Calculating the score using the impurity values and the two matrix elements. 6. The method of claim 5, wherein the score is determined using a fuzzy inference engine (fuzzy inference engine) based on the impurity values and the two matrix elements corresponding to the linkage. 7. The method of claim 2, wherein determining the first haplotype and the second haplotype using the score and the orientation comprises: based on the scores and orientations, a linkage map between pairs of heterozygous loci is optimized. 8. The method of claim 7, wherein the graph is optimized by generating a minimum spanning tree. 9. The method of claim 7, wherein optimizing the join graph provides a plurality of subtrees, the method further comprising: reducing each of the plurality of subtrees to contigs, thereby forming a plurality of contigs; and phasing a plurality of contigs using sequencing information from parents of the organism to generate the first haplotype and the second haplotype. 10. The method of claim 7, further comprising: removing the first hybrid locus as a node from the map when the first hybrid locus does not have at least two junctions with another hybrid locus in one direction and at least one junction with another hybrid locus in another direction. 11. The method of claim 1, wherein determining a matrix of shared aliquot numbers between alleles on reads at a particular pair of heterozygous loci comprises mapping reads to heterozygous loci of the particular pair and calculating mapped reads sharing aliquots between the alleles. 12. The method of claim 1, further comprising: generating, with the one or more computing devices, an assembly sequence of the first and second haplotypes. 13. A method of analyzing genomic DNA of an organism, the method comprising: receiving, at one or more computing devices, a plurality of reads corresponding to fragments of genomic DNA from a plurality of aliquots, each fragment of genomic DNA tagged with an aliquot-specific tag sequence, and each read comprising a sequence of a fragment from genomic DNA and an aliquot-specific tag sequence, wherein the genomic DNA contained in each aliquot of the plurality of aliquots is less than a haploid genomic equivalent; determining an aliquot from which the reads originate by identifying the aliquot-specific tag sequence; generating, with one or more computing devices, a plurality of assembly sequences aligned with overlapping regions of a genome of the organism, each assembly sequence in the overlapping regions corresponding to a different aliquot; Generating, with the one or more computing devices, a phased sequence from the reads as follows: identifying a plurality of heterozygous loci corresponding to at least a portion of the genome of the organism, wherein the plurality of heterozygous loci comprises N heterozygous loci, wherein N is an integer greater than 1; and is Phasing the plurality of heterozygous loci to generate a first haplotype and a second haplotype, the phasing using an aliquot of origin of reads corresponding to the plurality of heterozygous loci to determine which alleles at the heterozygous loci are on the same haplotype, the phased sequence corresponding to at least a portion of the genome of the organism, wherein phasing the plurality of heterozygous loci comprises: cluster 2 based on alleles at N heterozygous loci for the corresponding assembled sequenceNTo 4NA sequence of assemblies within a space of possibilities, thereby creating a plurality of clusters; and identifying two clusters with the highest density as corresponding to the first haplotype and the second haplotype. 14. The method of claim 13, wherein phasing the plurality of heterozygous loci comprises: calculating an N-dimensional matrix, each dimension corresponding to a heterozygous locus, wherein each matrix element corresponds to the number of assembled sequences having a combination of alleles corresponding to the matrix element; Identifying a first matrix element and a second matrix element, each being the center of one of the two clusters; determining the first haplotype at N heterozygous loci from the first matrix elements; and determining the second haplotype at N heterozygous loci from the second matrix elements. 15. The method of claim 14, further comprising: assigning a weight to each of the matrix elements, wherein a first weight of a first combination of alleles observed in the population of interest is greater than a second weight of a second combination of alleles observed in the population of interest. 16. The method of claim 13, further comprising: repeatedly phasing a plurality of regions, each region corresponding to a different plurality of heterozygous loci, thereby forming two contigs from the two clusters having the highest density for each of the plurality of regions, to obtain a plurality of contigs; and phasing the plurality of contigs using sequencing information from parents of an organism to generate the first haplotype and the second haplotype. 17. A method of analyzing genomic DNA of an organism, the method comprising: receiving, at one or more computing devices, a plurality of reads corresponding to fragments of genomic DNA from a plurality of aliquots, each fragment of genomic DNA tagged with an aliquot-specific tag sequence, and each read comprising a sequence of a fragment from genetic DNA and an aliquot-specific tag sequence, wherein the genomic DNA contained in each aliquot of the plurality of aliquots is less than a haploid genome equivalent; Determining an aliquot from which the reads originate by identifying the aliquot-specific tag sequence; generating, with the one or more computing devices, a phased sequence from the reads as follows: identifying a plurality of heterozygous loci corresponding to at least a portion of the organism's genome; and is Phasing the plurality of heterozygous loci to generate a first haplotype and a second haplotype, the phasing using an aliquot of origin of reads corresponding to the plurality of heterozygous loci to determine which alleles at the heterozygous loci are on the same haplotype, the phased sequence corresponding to at least a portion of the genome of the organism; identifying phased SNPs from a plurality of heterozygous loci, the phased SNPs having a first allele and a second allele; identifying a locus that is a neighbor of the phased SNP, wherein the locus has no response, the locus having reads with a third allele and a fourth allele; calculating a first number of shared aliquots comprising a first allele at the phased SNP and a third allele at the locus; and determining the third allele at the locus based on the first number of shared aliquots. 18. The method of claim 17, further comprising: determining that the third allele is located at the locus when the first number of shared aliquots is above a threshold, the threshold being 2 or higher. 19. The method of claim 17, further comprising: calculating a second number of shared aliquots comprising a second allele at the phasing SNP and a third allele at the locus; calculating a third number of shared aliquots comprising a first allele at the phased SNP and a fourth allele at the locus; and determining that the locus is homozygous for the third allele when the first and second numbers are above a threshold and the third number is below the threshold. 20. The method of claim 17, further comprising: calculating a second number of shared aliquots comprising a second allele at the phasing SNP and a fourth allele at the locus; determining that the locus is heterozygous for the third allele and the fourth allele when all reads harboring the third allele share an aliquot with the first allele and all reads harboring the fourth allele share an aliquot with the second allele. 21. A computer-readable storage medium storing instructions that, when executed by one or more computing devices, cause the one or more computing devices to perform the method of any of claims 1-20. 22. A computer system comprising the computer-readable storage medium of claim 21. 23. A computer system comprising one or more processors configured to perform the method of any one of claims 1-20. 24. Computer system comprising means (means) for performing the method of any one of claims 1 to 20. 25. A computer system, comprising: one or more computer-readable storage media storing an assembled fully human genomic sequence having no more than one pseudo single nucleotide variant per megabase and a response rate of at least 70%, wherein the assembled fully human genomic sequence is generated by sequencing between 1pg and 10ng of human genomic DNA.
